Model Type: DecisionTree

Training Size = 41841
Testing Size = 13947

Training Accuracy = 0.3545565354556535
Testing Accuracy = 0.31454793145479315

Training Average Error = 0.9579837957983796
Testing Average Error = 1.00516240051624

Training Recall = [0.2870004092211158, 0.5585626771509554, 0.2565821911054137, 0.30781119961954584, 0.28500298745269864]
Testing Recall = [0.2542869092429946, 0.5102040816326531, 0.2092492149586069, 0.27979094076655053, 0.2676737160120846]

Training f1 (micro, macro, weighted) = [0.3545565354556535, 0.3391974749620864, 0.36376931230237974]
Testing f1 (micro, macro, weighted) = [0.31454793145479315, 0.30215935704234387, 0.32386848647497174]

Training auc (macro, weighted) = [0.9858776361332687, 0.9839728890099751]
Testing auc (macro, weighted) = [0.985498762401047, 0.9837008942879621]

Hyper-Parameters: 

Max Tree Depth: 50
Max Tree Features: 30
Max Leaf Nodes: 150

Accuracy Score for Predicting on Training Data: 0.3546
Accuracy Score for Predicting on Test Data: 0.3145

Overall Average Probabilities
-------------------------------------
Section 1: 17.54%
Section 2: 26.06%
Section 3: 24.21%
Section 4: 20.12%
Section 5: 12.07%

Field Slice Counts for Training Data
--------------------------------------------------
Section	Truth	Prediction
1		7331		5663
2		10937		17238
3		10141		7592
4		8411		7291
5		5021		4057
Amount Correct: 14835
Amount Incorrect: 27006

Field Slice Counts for Testing Data
--------------------------------------------------
Section	Truth	Prediction
1		2391		1901
2		3528		5719
3		3503		2524
4		2870		2412
5		1655		1391
Amount Correct: 4387
Amount Incorrect: 9560
