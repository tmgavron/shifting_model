Model Type: DecisionTree

Training Size = 41841
Testing Size = 13947

Training Accuracy = 0.3552974355297436
Testing Accuracy = 0.3094572309457231

Training Average Error = 0.9771276977127697
Testing Average Error = 1.0394350039435003

Training Recall = [0.35970435258691486, 0.5288408716352316, 0.20826364977865225, 0.3410623447296818, 0.2926926926926927]
Testing Recall = [0.3253311258278146, 0.47473892181766864, 0.16728945099166428, 0.29773691654879775, 0.25223081499107675]

Training f1 (micro, macro, weighted) = [0.35529743552974363, 0.3426712721951479, 0.3647749489250366]
Testing f1 (micro, macro, weighted) = [0.3094572309457231, 0.29859451869312037, 0.31939560909800574]

Training auc (macro, weighted) = [0.9833612984814254, 0.9756104733261343]
Testing auc (macro, weighted) = [0.9831101481349117, 0.9752495909221135]

Hyper-Parameters: 

Max Tree Depth: 50
Max Tree Features: 30
Max Leaf Nodes: 150

Accuracy Score for Predicting on Training Data: 0.3553
Accuracy Score for Predicting on Test Data: 0.3095

Overall Average Probabilities
-------------------------------------
Section 1: 17.59%
Section 2: 26.18%
Section 3: 24.27%
Section 4: 20.10%
Section 5: 11.85%

Field Slice Counts for Training Data
--------------------------------------------------
Section	Truth	Prediction
1		7306		7376
2		10922		16288
3		10165		5980
4		8453		8001
5		4995		4196
Amount Correct: 14866
Amount Incorrect: 26975

Field Slice Counts for Testing Data
--------------------------------------------------
Section	Truth	Prediction
1		2416		2504
2		3543		5410
3		3479		2025
4		2828		2644
5		1681		1364
Amount Correct: 4316
Amount Incorrect: 9631
