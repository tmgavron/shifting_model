{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training:\n",
    "# 1) Load all data from preprocessing (training/test splits, etc)\n",
    "# 2) Begin Training Models\n",
    "    #  a) Decision Tree\n",
    "    #  b) Naive Bayes\n",
    "    #  c) Logistic Regression\n",
    "    #  d) SVM\n",
    "# 3) Testing Models\n",
    "# 4) New Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from Models import ModelUtil\n",
    "from Data import Preprocessing, DataUtil\n",
    "from Visualization import VisualUtil\n",
    "from Logs import logging as logs\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import configparser\n",
    "import numpy as np\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('Data//config.ini')\n",
    "\n",
    "importlib.reload(Preprocessing)\n",
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(VisualUtil)\n",
    "importlib.reload(logs)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load all data from preprocessing \n",
    "importlib.reload(Preprocessing)\n",
    "\n",
    "if(\"False\" in config['DATA']['USE_NEW_PREPROCESSING']):\n",
    "    infieldDataFrame, outfieldDataFrame = Preprocessing.dataFiltering([], False)\n",
    "\n",
    "    # drop nan values from the used columns\n",
    "    specific_columns = [\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"PlateLocHeight\", \"PlateLocSide\", \"ZoneSpeed\", \"SpinRate\", \"RelSpeed\", \"HorzBreak\", \"VertBreak\"]\n",
    "    infieldDataFrame = infieldDataFrame.dropna(axis=0, how='any',subset=specific_columns)\n",
    "\n",
    "else:\n",
    "    normDataFrame = Preprocessing.dataProcessing()\n",
    "    infieldDataFrame, outfieldDataFrame = Preprocessing.dataFiltering(normDataFrame, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infieldcorrmatrix = infieldDataFrame.corr()\n",
    "infieldcorrmatrix.to_csv('Infield_Correlation_Matrix')\n",
    "outfieldcorrmatrix = outfieldDataFrame.corr()\n",
    "outfieldcorrmatrix.to_csv('Outfield_Correlation_Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Class Splits (count, then percentage):\n",
      "[7280, 10890, 10257, 8471, 4956]\n",
      "[0.1739, 0.2602, 0.2451, 0.2024, 0.1184]\n",
      "\n",
      "Testing Class Splits (count, then percentage):\n",
      "[2444, 3583, 3391, 2813, 1721]\n",
      "[0.1752, 0.2568, 0.243, 0.2016, 0.1234]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(Preprocessing)\n",
    "\n",
    "if(\"False\" in config['DATA']['USE_NEW_PREPROCESSING']):\n",
    "    Y = infieldDataFrame[\"FieldSlice\"]\n",
    "    X = infieldDataFrame[[\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"PlateLocHeight\", \"PlateLocSide\", \"ZoneSpeed\", \"SpinRate\", \"RelSpeed\", \"HorzBreak\", \"VertBreak\"]] \n",
    "    X = DataUtil.normalizeData(X)\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.25, random_state=11)\n",
    "    # adb = AdaBoostClassifier()\n",
    "    # adb_model = adb.fit(xTrain, yTrain)\n",
    "\n",
    "    # calculate split information:\n",
    "    trainingClassSplit = [0, 0, 0, 0, 0]\n",
    "    for i in yTrain:\n",
    "        trainingClassSplit[i-1] += 1\n",
    "\n",
    "    \n",
    "    testingClassSplit = [0, 0, 0, 0, 0]\n",
    "    for i in yTest:\n",
    "        testingClassSplit[i-1] += 1\n",
    "\n",
    "    trainingClassPercent = []\n",
    "    for i in trainingClassSplit:\n",
    "        trainingClassPercent.append(round(i/len(yTrain), 4))\n",
    "\n",
    "    testingClassPercent = []\n",
    "    for i in testingClassSplit:\n",
    "        testingClassPercent.append(round(i/len(yTest), 4))\n",
    "\n",
    "    print(\"Training Class Splits (count, then percentage):\")\n",
    "    print(trainingClassSplit)\n",
    "    print(trainingClassPercent)\n",
    "    print(\"\\nTesting Class Splits (count, then percentage):\")\n",
    "    print(testingClassSplit)\n",
    "    print(testingClassPercent)\n",
    "else:\n",
    "    infieldY = infieldDataFrame[0][['Direction','Distance']]\n",
    "    infieldX = infieldDataFrame[0][infieldDataFrame[1]] \n",
    "    if(\"True\" in config['SPLIT']['TTS']):\n",
    "        xTrain, xTest, yTrain, yTest = train_test_split(infieldX, infieldY, test_size=0.20, random_state=11)\n",
    "        \n",
    "    elif(\"True\" in config['SPLIT']['KFold']):\n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "        for train_index, test_index in kf.split(infieldX):\n",
    "            xTrain, xTest = infieldX.iloc[train_index,:], infieldX.iloc[test_index,:]\n",
    "            yTrain, yTest = infieldY.iloc[train_index,:], infieldY.iloc[test_index,:]\n",
    "\n",
    "    elif(\"True\" in config['SPLIT']['LOOCV']):\n",
    "        loo = LeaveOneOut()\n",
    "        for train_index, test_index in loo.split(infieldX):\n",
    "            xTrain, xTest = infieldX.iloc[train_index,:], infieldX.iloc[test_index,:]\n",
    "            yTrain, yTest = infieldY.iloc[train_index,:], infieldY.iloc[test_index,:]\n",
    "\n",
    "    else:\n",
    "        print(\"No Splitting Method Selected\")\n",
    "        \n",
    "\n",
    "# GroupKFold: (avoids putting data from the same group in the test set -- useful for Pitcher/Batter ID when we implement that.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training decision tree model...\n",
      "done!\n",
      "getting statistics...\n",
      "\n",
      "printing statistics...\n",
      "Model Type: DecisionTree\n",
      "\n",
      "Training Size = 41854\n",
      "Testing Size = 13952\n",
      "\n",
      "Training Accuracy = 0.36718115353371245\n",
      "Testing Accuracy = 0.3353641055045872\n",
      "\n",
      "Training Average Error = 0.9165910068332775\n",
      "Testing Average Error = 0.9595040137614679\n",
      "\n",
      "Training Recall = [0.27225274725274723, 0.5891643709825528, 0.30135517207760554, 0.29229134694841225, 0.283091202582728]\n",
      "Testing Recall = [0.2295417348608838, 0.5540050237231371, 0.2695370097316426, 0.2694632065410594, 0.26786751888436955]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.36718115353371245, 0.3498229078263638, 0.377188837360659]\n",
      "Testing f1 (micro, macro, weighted) = [0.3353641055045872, 0.31898396185209704, 0.3458779663848676]\n",
      "\n",
      "Training auc (macro, weighted) = [0.9919328682635605, 0.9890802485874709]\n",
      "Testing auc (macro, weighted) = [0.9919480570866608, 0.9889777955420621]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Max Tree Depth: 50\n",
      "Max Tree Features: 30\n",
      "Max Leaf Nodes: 150\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 0.9166\n",
      "Accuracy Score for Predicting on Test Data: 0.3354\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 17.27%\n",
      "Section 2: 25.96%\n",
      "Section 3: 24.58%\n",
      "Section 4: 20.30%\n",
      "Section 5: 11.89%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7280\t\t4849\n",
      "2\t\t10890\t\t17819\n",
      "3\t\t10257\t\t8892\n",
      "4\t\t8471\t\t6569\n",
      "5\t\t4956\t\t3725\n",
      "Amount Correct: 15368\n",
      "Amount Incorrect: 26486\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2444\t\t1562\n",
      "2\t\t3583\t\t5974\n",
      "3\t\t3391\t\t2943\n",
      "4\t\t2813\t\t2211\n",
      "5\t\t1721\t\t1262\n",
      "Amount Correct: 4679\n",
      "Amount Incorrect: 9273\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# a) Decision Tree\n",
    "# Need to test these hyperparameters for best case\n",
    "max_depth = 50\n",
    "max_features = 30\n",
    "max_leaf_nodes = 150\n",
    "dtOutput = ModelUtil.runDT(xTrain, yTrain, xTest, yTest, max_depth, max_features, max_leaf_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Naive Bayes model...\n",
      "done!\n",
      "getting statistics...\n",
      "printing statistics...\n",
      "Model Type: NaiveBayes\n",
      "\n",
      "Training Size = 41854\n",
      "Testing Size = 13952\n",
      "\n",
      "Training Accuracy = 0.29932622927318775\n",
      "Testing Accuracy = 0.30124713302752293\n",
      "\n",
      "Training Average Error = 1.0603048693075932\n",
      "Testing Average Error = 1.0596330275229358\n",
      "\n",
      "Training Recall = [0.3501373626373626, 0.26483011937557394, 0.28565857463195865, 0.3834258056900012, 0.1850282485875706]\n",
      "Testing Recall = [0.3473813420621931, 0.26960647502093216, 0.28870539663815986, 0.3775328830430146, 0.20162696106914585]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.29932622927318775, 0.29279114174307147, 0.3021302145504058]\n",
      "Testing f1 (micro, macro, weighted) = [0.30124713302752293, 0.29704959345347176, 0.303421573090737]\n",
      "\n",
      "Training auc (macro, weighted) = [0.9796107525553882, 0.9745492787123667]\n",
      "Testing auc (macro, weighted) = [0.9801851479792166, 0.9750596891616053]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Var Smoothing: 1e-09\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 1.0603\n",
      "Accuracy Score for Predicting on Test Data: 0.3012\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 20.34%\n",
      "Section 2: 22.29%\n",
      "Section 3: 24.90%\n",
      "Section 4: 21.35%\n",
      "Section 5: 11.12%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7280\t\t8546\n",
      "2\t\t10890\t\t8731\n",
      "3\t\t10257\t\t11215\n",
      "4\t\t8471\t\t10314\n",
      "5\t\t4956\t\t3048\n",
      "Amount Correct: 12528\n",
      "Amount Incorrect: 29326\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2444\t\t2756\n",
      "2\t\t3583\t\t2956\n",
      "3\t\t3391\t\t3736\n",
      "4\t\t2813\t\t3430\n",
      "5\t\t1721\t\t1074\n",
      "Amount Correct: 4203\n",
      "Amount Incorrect: 9749\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# b) Naive Bayes\n",
    "\n",
    "var_smoothing = 1e-9\n",
    "nbOutput = ModelUtil.runNB(xTrain, yTrain, xTest, yTest, var_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training logistic regression model...\n",
      "done!\n",
      "getting statistics...\n",
      "printing statistics...\n",
      "Model Type: LogisticRegression\n",
      "\n",
      "Training Size = 41854\n",
      "Testing Size = 13952\n",
      "\n",
      "Training Accuracy = 0.3336598652458546\n",
      "Testing Accuracy = 0.3320670871559633\n",
      "\n",
      "Training Average Error = 0.9501839728580302\n",
      "Testing Average Error = 0.9519065366972477\n",
      "\n",
      "Training Recall = [0.19945054945054946, 0.6603305785123967, 0.08092034708004289, 0.4730256168102939, 0.09786117836965294]\n",
      "Testing Recall = [0.20662847790507366, 0.6502930505163271, 0.08728988498967856, 0.47707074297902596, 0.09296920395119117]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.3336598652458546, 0.2742870861830683, 0.3793637661152824]\n",
      "Testing f1 (micro, macro, weighted) = [0.3320670871559633, 0.27532402620013113, 0.37606800677094027]\n",
      "\n",
      "Training auc (macro, weighted) = [0.9693485792190861, 0.9519703671146772]\n",
      "Testing auc (macro, weighted) = [0.9696370401980529, 0.953305452126292]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Learning Rate: 0.8\n",
      "Epochs: 100\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 0.9502\n",
      "Accuracy Score for Predicting on Test Data: 0.3321\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 17.34%\n",
      "Section 2: 26.01%\n",
      "Section 3: 24.54%\n",
      "Section 4: 20.27%\n",
      "Section 5: 11.84%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7280\t\t3869\n",
      "2\t\t10890\t\t21609\n",
      "3\t\t10257\t\t2716\n",
      "4\t\t8471\t\t12463\n",
      "5\t\t4956\t\t1197\n",
      "Amount Correct: 13965\n",
      "Amount Incorrect: 27889\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2444\t\t1289\n",
      "2\t\t3583\t\t7151\n",
      "3\t\t3391\t\t922\n",
      "4\t\t2813\t\t4220\n",
      "5\t\t1721\t\t370\n",
      "Amount Correct: 4633\n",
      "Amount Incorrect: 9319\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# c)Logistic Regression\n",
    "lr = 0.8\n",
    "e = 100\n",
    "logRegOutput = ModelUtil.runLogReg(xTrain, yTrain, xTest, yTest, lr, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM model...\n",
      "done!\n",
      "getting statistics...\n",
      "logging statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:71: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats = dftest.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:75: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:77: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats = dftrain.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:81: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing statistics...\n",
      "Model Type: SVM\n",
      "\n",
      "Training Size = 42213\n",
      "Testing Size = 14072\n",
      "\n",
      "Training Accuracy = 0.31333949257337784\n",
      "Testing Accuracy = 0.32227117680500283\n",
      "\n",
      "Training Average Error = 0.9562220169142207\n",
      "Testing Average Error = 0.9404491188175099\n",
      "\n",
      "Training Recall = [0.0, 0.8033190480532506, 0.0, 0.5206884356949193, 0.0]\n",
      "Testing Recall = [0.0, 0.8188306340927807, 0.0, 0.5387018396390142, 0.0]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.31333949257337784, 0.16828958750340162, 0.43098074084009164]\n",
      "Testing f1 (micro, macro, weighted) = [0.32227117680500283, 0.17354902523824683, 0.44205483936829404]\n",
      "\n",
      "Training auc (macro, weighted) = Error\n",
      "Testing auc (macro, weighted) = Error\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Regularization Constant: 1\n",
      "Kernel Type: linear\n",
      "Kernel Degree1\n",
      "Kernel Coefficient (gamma): scale\n",
      "Independent Term in Kernel (coef0): 0.0\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 0.9562\n",
      "Accuracy Score for Predicting on Test Data: 0.3223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:172: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats = dftest.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:176: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:178: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats = dftrain.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:182: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 16.61%\n",
      "Section 2: 26.53%\n",
      "Section 3: 25.04%\n",
      "Section 4: 20.27%\n",
      "Section 5: 11.55%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7295\t\t28007.0\n",
      "2\t\t10967\t\t14206.0\n",
      "3\t\t10348\t\tnan\n",
      "4\t\t8483\t\tnan\n",
      "5\t\t5120\t\tnan\n",
      "Amount Correct: 13227\n",
      "Amount Incorrect: 28986\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2513\t\t9367.0\n",
      "2\t\t3643\t\t4705.0\n",
      "3\t\t3427\t\tnan\n",
      "4\t\t2881\t\tnan\n",
      "5\t\t1608\t\tnan\n",
      "Amount Correct: 4535\n",
      "Amount Incorrect: 9537\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# d) SVM\n",
    "rC = 1\n",
    "kernel='linear'\n",
    "degree= 1\n",
    "gamma= 'scale'\n",
    "coef0= 0.0\n",
    "svmOutput = ModelUtil.runSVM(xTrain, yTrain, xTest, yTest, rC, kernel, degree, gamma, coef0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z) RandomForestRegressor\n",
    "for i in range(0, len(trainIn)):\n",
    "    direction, distance = ModelUtil.runRFR(trainIn[i], trainOut[i], testIn[i], testOut[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Output: \n",
      "Actual Field Slice: \t\t1\n",
      "\n",
      "Decision Tree:\n",
      "Predicted Field Slice: \t\t2\n",
      "Field Slice Probabilities: \t[0.23381643 0.35942029 0.22995169 0.12173913 0.05507246]\n",
      "\n",
      "Naive Bayes:\n",
      "Predicted Field Slice: \t\t2\n",
      "Field Slice Probabilities: \t[0.14106099 0.31966119 0.30380781 0.18913204 0.04633797]\n",
      "\n",
      "Logistic Regression:\n",
      "Predicted Field Slice: \t\t2\n",
      "Field Slice Probabilities: \t[0.21911846 0.33834919 0.24991333 0.14666562 0.0459534 ]\n",
      "\n",
      "\n",
      "AVG Prediction: \t\t2\n",
      "Field Slice AVG Probabilities: \t[0.19799862 0.33914356 0.26122428 0.15251227 0.04912128]\n"
     ]
    }
   ],
   "source": [
    "# Change the value of index to look at different datapoints\n",
    "importlib.reload(VisualUtil)\n",
    "# 3) Model Testing:\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "\n",
    "print(\"Testing Output: \")\n",
    "# index of test value:\n",
    "index = 6432\n",
    "print(f\"Actual Field Slice: \\t\\t{yTest.iloc[index]}\")\n",
    "\n",
    "print(\"\\nDecision Tree:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{dt.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{dt.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "print(\"\\nNaive Bayes:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{nb.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{nb.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{logReg.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{logReg.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "# print(\"\\nSVM:\")\n",
    "# print(f\"Predicted Field Slice: \\t\\t{svm.predict([xTest.iloc[index]])[0]}\")\n",
    "# print(f\"Field Slice Probabilities: \\t{svm.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "averageProbs = dt.predict_proba([xTest.iloc[index]])[0] + nb.predict_proba([xTest.iloc[index]])[0] + logReg.predict_proba([xTest.iloc[index]])[0] # + svm.predict_proba([xTest.iloc[index]])[0]\n",
    "averageProbs = averageProbs / 3 \n",
    "\n",
    "print(f\"\\n\\nAVG Prediction: \\t\\t{np.argmax(averageProbs)+1}\")\n",
    "print(f\"Field Slice AVG Probabilities: \\t{averageProbs}\")\n",
    "\n",
    "VisualUtil.visualizeData(averageProbs, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4538\n",
      "9414\n",
      "0.2064765880034086\n",
      "1.4736562566390483\n"
     ]
    }
   ],
   "source": [
    "# Gather data on average predictions\n",
    "length = len(xTest)\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "wrongProbs = 0\n",
    "wrongDistance = 0\n",
    "\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "for index in range(length):\n",
    "    averageProbs = dt.predict_proba([xTest.iloc[index]])[0] + nb.predict_proba([xTest.iloc[index]])[0] + logReg.predict_proba([xTest.iloc[index]])[0] #+ svm.predict_proba([xTest.iloc[index]])[0]\n",
    "    averageProbs = averageProbs / 3\n",
    "\n",
    "    actual = yTest.iloc[index]\n",
    "    predicted = np.argmax(averageProbs)+1\n",
    "\n",
    "    percentageActual = averageProbs[actual-1]\n",
    "\n",
    "    if predicted == actual:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1 \n",
    "        wrongProbs += percentageActual\n",
    "        wrongDistance += abs(actual-predicted)\n",
    "\n",
    "\n",
    "# Correct Prediction Count\n",
    "print(correct)\n",
    "# Incorrect Prediction Count\n",
    "print(incorrect)\n",
    "# Average probability of actual slice when guess is incorrect\n",
    "print(wrongProbs/incorrect)\n",
    "# Average distance from actual slice to guess slice when guess is incorrect\n",
    "print(wrongDistance/incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Model Iterations and Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Data Visualization\n",
    "\n",
    "# Temporary method of getting percentages for testing purposes\n",
    "infieldPercentages  = np.random.dirichlet(np.ones(4), size=1)[0]\n",
    "outfieldPercentages = np.random.dirichlet(np.ones(1), size=1)[0]\n",
    "\n",
    "VisualUtil.visualizeData(infieldPercentages, outfieldPercentages)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
