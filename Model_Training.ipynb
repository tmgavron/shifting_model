{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training:\n",
    "# 1) Load all data from preprocessing (training/test splits, etc)\n",
    "# 2) Begin Training Models\n",
    "    #  a) Decision Tree\n",
    "    #  b) Naive Bayes\n",
    "    #  c) Logistic Regression\n",
    "    #  d) SVM\n",
    "# 3) Testing Models\n",
    "# 4) New Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from Models import ModelUtil\n",
    "from Data import Preprocessing, DataUtil\n",
    "from Visualization import VisualUtil, batch_image_to_excel\n",
    "from Logs import logging as logs\n",
    "\n",
    "import importlib\n",
    "import configparser\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('Data//config.ini')\n",
    "\n",
    "importlib.reload(Preprocessing)\n",
    "importlib.reload(ModelUtil)\n",
    "# importlib.reload(VisualUtil)\n",
    "# importlib.reload(batch_image_to_excel)\n",
    "importlib.reload(logs)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load all data from preprocessing \n",
    "importlib.reload(Preprocessing)\n",
    "newprocessing = 'True' in config['DATA']['USE_NEW_PREPROCESSING']\n",
    "infieldDataFrame, outfieldDataFrame = Preprocessing.dataFiltering([], newprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of Empty DataFrame\n",
      "Columns: [PitcherThrows, BatterSide, TaggedPitchType, PlateLocHeight, PlateLocSide, ZoneSpeed, RelSpeed, VertRelAngle, HorzRelAngle, SpinRate, SpinAxis, RelHeight, RelSide, VertBreak, InducedVertBreak, HorzBreak, VertApprAngle, HorzApprAngle, Extension, FieldSection, PitcherTeam]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 21 columns]>\n",
      "<bound method NDFrame.head of Empty DataFrame\n",
      "Columns: [PitcherThrows, BatterSide, TaggedPitchType, PlateLocHeight, PlateLocSide, ZoneSpeed, RelSpeed, VertRelAngle, HorzRelAngle, SpinRate, SpinAxis, RelHeight, RelSide, VertBreak, InducedVertBreak, HorzBreak, VertApprAngle, HorzApprAngle, Extension, FieldSlice, PitcherTeam]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 21 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(outfieldDataFrame.head)\n",
    "print(infieldDataFrame.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of this is mapping the strings to numbers for both infieldDataFrame and outfieldDataFrame so that the correlation matrix can be computed\n",
    "# This can most likely be moved to a method in the logging.py file\n",
    "infieldDF4Matrix = infieldDataFrame.copy()\n",
    "outfieldDF4Matrix = outfieldDataFrame.copy()\n",
    "strColumns = [] \n",
    "for cName in outfieldDF4Matrix.columns:\n",
    "    if(str(outfieldDF4Matrix[cName].dtype) in 'object'):\n",
    "        strColumns.append(cName)\n",
    "rValueDict = {}\n",
    "for cName in strColumns:\n",
    "    i = 0\n",
    "    infieldUniques = infieldDF4Matrix[cName].unique()\n",
    "    for rValue in infieldUniques:\n",
    "        rValueDict.update({rValue:i})\n",
    "        i+=1\n",
    "    infieldDF4Matrix[cName] = infieldDF4Matrix[cName].map(rValueDict)\n",
    "    uniqueVals = [x for x in outfieldDF4Matrix[cName].unique() if x not in infieldUniques]\n",
    "    for rValue in uniqueVals: \n",
    "        rValueDict.update({rValue:i})\n",
    "        i+=1\n",
    "    outfieldDF4Matrix[cName] = outfieldDF4Matrix[cName].map(rValueDict)\n",
    "infieldDF4Matrix = infieldDF4Matrix.replace(np.nan, 0)\n",
    "infieldDF4Matrix = infieldDF4Matrix.replace('', 0)\n",
    "outfieldDF4Matrix = outfieldDF4Matrix.replace(np.nan, 0)\n",
    "outfieldDF4Matrix = outfieldDF4Matrix.replace('', 0)\n",
    "\n",
    "# Correlation does not imply causation.\n",
    "# -1 means that the 2 variables have an inverse linear relationship: when X increases, Y decreases\n",
    "# 0 means no linear correlation between X and Y\n",
    "# 1 means that the 2 variables have a linear relationship: when X increases, Y increases too.\n",
    "infieldcorrmatrix = infieldDF4Matrix.corr()\n",
    "outfieldcorrmatrix = outfieldDF4Matrix.corr()\n",
    "if (config['LOGGING']['Excel'] == 'True'):\n",
    "    logs.writeToExcelSheet(infieldcorrmatrix, \"Infield Correlation Matrix\")\n",
    "    logs.writeToExcelSheet(outfieldcorrmatrix, \"Outfield Correlation Matrix\")\n",
    "if (config['LOGGING']['Debug'] == 'True'):\n",
    "    print(infieldcorrmatrix)\n",
    "    print(outfieldcorrmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Class Splits (count, then percentage):\n",
      "[2694, 2596, 2621, 2310, 3637, 4694, 4728, 4785, 3834, 2210, 4143, 4675, 3574, 1647, 2551]\n",
      "[0.0531, 0.0512, 0.0517, 0.0456, 0.0717, 0.0926, 0.0933, 0.0944, 0.0756, 0.0436, 0.0817, 0.0922, 0.0705, 0.0325, 0.0503]\n",
      "\n",
      "Testing Class Splits (count, then percentage):\n",
      "[878, 853, 953, 722, 1205, 1553, 1489, 1648, 1336, 700, 1299, 1518, 1254, 567, 925]\n",
      "[0.052, 0.0505, 0.0564, 0.0427, 0.0713, 0.0919, 0.0881, 0.0975, 0.0791, 0.0414, 0.0769, 0.0898, 0.0742, 0.0336, 0.0547]\n",
      "<bound method NDFrame.head of 593248     13\n",
      "861391      9\n",
      "479332      0\n",
      "227915      7\n",
      "1062950     6\n",
      "           ..\n",
      "554602     12\n",
      "1328274    13\n",
      "393693     14\n",
      "661917     12\n",
      "183317      7\n",
      "Name: FieldSection, Length: 50699, dtype: int8>\n",
      "training decision tree model...\n",
      "done!\n",
      "getting statistics...\n",
      "\n",
      "logging statistics...\n",
      "printing statistics...\n",
      "Model Type: DecisionTree\n",
      "\n",
      "Training Size = 50699\n",
      "Testing Size = 16900\n",
      "\n",
      "Training Accuracy = 0.13929268821870253\n",
      "Testing Accuracy = 0.1101775147928994\n",
      "\n",
      "Training Average Error = 3.8359928203712106\n",
      "Testing Average Error = 3.9685798816568045\n",
      "\n",
      "Training Recall = [0.005567928730512249, 0.01694915254237288, 0.006104540251812286, 0.06623376623376623, 0.22133626615342314, 0.13187047294418405, 0.21637055837563451, 0.2231974921630094, 0.229264475743349, 0.03619909502262444, 0.13999517258025584, 0.2849197860962567, 0.059597090095131505, 0.0, 0.09212073696589573]\n",
      "Testing Recall = [0.0, 0.008206330597889801, 0.001049317943336831, 0.05124653739612189, 0.16431535269709543, 0.10367031551835158, 0.17797179314976494, 0.18143203883495146, 0.18263473053892215, 0.02142857142857143, 0.12471131639722864, 0.23451910408432147, 0.04066985645933014, 0.0, 0.07135135135135136]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.13929268821870253, 0.1034512000587393, 0.15879225503750216]\n",
      "Testing f1 (micro, macro, weighted) = [0.1101775147928994, 0.07952076878375698, 0.12719200543974188]\n",
      "\n",
      "Training auc (macro, weighted) = Error\n",
      "Testing auc (macro, weighted) = Error\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Max Tree Depth: 50\n",
      "Max Tree Features: 30\n",
      "Max Leaf Nodes: 150\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 3.8360\n",
      "Accuracy Score for Predicting on Test Data: 0.1102\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 6: 5.01%\n",
      "Section 7: 5.30%\n",
      "Section 8: 5.12%\n",
      "Section 9: 5.17%\n",
      "Section 10: 4.54%%\n",
      "Section 11: 7.24%\n",
      "Section 12: 9.29%\n",
      "Section 13: 9.35%\n",
      "Section 14: 9.39%\n",
      "Section 15: 7.54%\n",
      "Section 16: 4.37%%\n",
      "Section 17: 8.20%\n",
      "Section 18: 9.20%\n",
      "Section 19: 7.04%%\n",
      "Section 20: 3.23%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "6\t\t2551\t\t1937.0\n",
      "7\t\t2694\t\t18.0\n",
      "8\t\t2596\t\t184.0\n",
      "9\t\t2621\t\t23.0\n",
      "10\t\t2310\t\t1284.0\n",
      "11\t\t3637\t\t4980.0\n",
      "12\t\t4694\t\t4383.0\n",
      "13\t\t4728\t\t8491.0\n",
      "14\t\t4785\t\t7296.0\n",
      "15\t\t3834\t\t4933.0\n",
      "16\t\t2210\t\t463.0\n",
      "17\t\t4143\t\t4391.0\n",
      "18\t\t4675\t\t10822.0\n",
      "19\t\t3574\t\t1494.0\n",
      "20\t\t1647\t\tnan\n",
      "Amount Correct: 7062\n",
      "Amount Incorrect: 43637\n",
      "\n",
      "Field Section Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "6\t\t925\t\t615.0\n",
      "7\t\t878\t\t4.0\n",
      "8\t\t853\t\t59.0\n",
      "9\t\t953\t\t7.0\n",
      "10\t\t722\t\t419.0\n",
      "11\t\t1205\t\t1704.0\n",
      "12\t\t1553\t\t1453.0\n",
      "13\t\t1489\t\t2907.0\n",
      "14\t\t1648\t\t2400.0\n",
      "15\t\t1336\t\t1682.0\n",
      "16\t\t700\t\t155.0\n",
      "17\t\t1299\t\t1464.0\n",
      "18\t\t1518\t\t3540.0\n",
      "19\t\t1254\t\t491.0\n",
      "20\t\t567\t\tnan\n",
      "Amount Correct: 1862\n",
      "Amount Incorrect: 15038\n",
      "exporting statistics to Excel...\n",
      "done!\n",
      "training Naive Bayes model...\n",
      "done!\n",
      "getting statistics...\n",
      "logging statistics...\n",
      "printing statistics...\n",
      "Model Type: NaiveBayes\n",
      "\n",
      "Training Size = 50699\n",
      "Testing Size = 16900\n",
      "\n",
      "Training Accuracy = 0.09990335115091027\n",
      "Testing Accuracy = 0.09958579881656805\n",
      "\n",
      "Training Average Error = 4.6181778733308345\n",
      "Testing Average Error = 4.637337278106509\n",
      "\n",
      "Training Recall = [0.006310319227913883, 0.0, 0.0, 0.0, 0.020071487489689305, 0.10353642948444823, 0.03193739424703892, 0.1387669801462905, 0.17188315075639019, 0.0, 0.04561911658218682, 0.4453475935828877, 0.0685506435366536, 0.0, 0.195609564876519]\n",
      "Testing Recall = [0.0056947608200455585, 0.0, 0.0, 0.0, 0.024066390041493777, 0.09916291049581455, 0.02887844190732035, 0.13228155339805825, 0.17964071856287425, 0.0, 0.04157043879907621, 0.4367588932806324, 0.09090909090909091, 0.0, 0.17621621621621622]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.09990335115091027, 0.05824126544739473, 0.12889357125814202]\n",
      "Testing f1 (micro, macro, weighted) = [0.09958579881656805, 0.05881917918884559, 0.12726117845189952]\n",
      "\n",
      "Training auc (macro, weighted) = Error\n",
      "Testing auc (macro, weighted) = Error\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Var Smoothing: 1e-09\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 4.6182\n",
      "Accuracy Score for Predicting on Test Data: 0.0996\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 6: 6.59%\n",
      "Section 7: 5.23%\n",
      "Section 8: 5.07%\n",
      "Section 9: 4.83%\n",
      "Section 10: 4.25%%\n",
      "Section 11: 6.75%\n",
      "Section 12: 8.66%\n",
      "Section 13: 8.80%\n",
      "Section 14: 8.90%\n",
      "Section 15: 7.40%\n",
      "Section 16: 4.04%%\n",
      "Section 17: 8.19%\n",
      "Section 18: 9.51%\n",
      "Section 19: 8.02%%\n",
      "Section 20: 3.76%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "6\t\t2551\t\t7160.0\n",
      "7\t\t2694\t\t169.0\n",
      "8\t\t2596\t\t2.0\n",
      "9\t\t2621\t\t866.0\n",
      "10\t\t2310\t\t3950.0\n",
      "11\t\t3637\t\t1371.0\n",
      "12\t\t4694\t\t5830.0\n",
      "13\t\t4728\t\t5690.0\n",
      "14\t\t4785\t\t2.0\n",
      "15\t\t3834\t\t1806.0\n",
      "16\t\t2210\t\t20833.0\n",
      "17\t\t4143\t\t3020.0\n",
      "18\t\t4675\t\tnan\n",
      "19\t\t3574\t\tnan\n",
      "20\t\t1647\t\tnan\n",
      "Amount Correct: 5065\n",
      "Amount Incorrect: 45634\n",
      "\n",
      "Field Section Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "6\t\t925\t\t2460.0\n",
      "7\t\t878\t\t48.0\n",
      "8\t\t853\t\t282.0\n",
      "9\t\t953\t\t1308.0\n",
      "10\t\t722\t\t474.0\n",
      "11\t\t1205\t\t1987.0\n",
      "12\t\t1553\t\t1875.0\n",
      "13\t\t1489\t\t638.0\n",
      "14\t\t1648\t\t6808.0\n",
      "15\t\t1336\t\t1020.0\n",
      "16\t\t700\t\tnan\n",
      "17\t\t1299\t\tnan\n",
      "18\t\t1518\t\tnan\n",
      "19\t\t1254\t\tnan\n",
      "20\t\t567\t\tnan\n",
      "Amount Correct: 1683\n",
      "Amount Incorrect: 15217\n",
      "exporting statistics to Excel...\n",
      "done!\n",
      "training logistic regression model...\n",
      "done!\n",
      "getting statistics...\n",
      "logging statistics...\n",
      "printing statistics...\n",
      "Model Type: LogisticRegression\n",
      "\n",
      "Training Size = 50699\n",
      "Testing Size = 16900\n",
      "\n",
      "Training Accuracy = 0.11968677883192963\n",
      "Testing Accuracy = 0.11775147928994083\n",
      "\n",
      "Training Average Error = 3.6302293930846763\n",
      "Testing Average Error = 3.6524852071005918\n",
      "\n",
      "Training Recall = [0.0, 0.0003852080123266564, 0.0, 0.0, 0.10750618641737696, 0.32765232211333617, 0.08375634517766498, 0.41567398119122256, 0.1343244653103808, 0.04932126696832579, 0.15351194786386677, 0.07614973262032086, 0.028819250139899274, 0.0, 0.013328106624852998]\n",
      "Testing Recall = [0.0, 0.0, 0.0, 0.0, 0.10622406639004149, 0.3419188667095943, 0.08663532572196105, 0.4029126213592233, 0.12050898203592815, 0.045714285714285714, 0.13163972286374134, 0.07444005270092227, 0.03508771929824561, 0.0, 0.018378378378378378]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.11968677883192963, 0.07227219527512282, 0.15085150769609412]\n",
      "Testing f1 (micro, macro, weighted) = [0.11775147928994083, 0.0709487889748698, 0.14877643726466067]\n",
      "\n",
      "Training auc (macro, weighted) = Error\n",
      "Testing auc (macro, weighted) = Error\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Learning Rate: 0.8\n",
      "Epochs: 100\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 3.6302\n",
      "Accuracy Score for Predicting on Test Data: 0.1178\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 6: 5.13%\n",
      "Section 7: 5.38%\n",
      "Section 8: 5.20%\n",
      "Section 9: 5.22%\n",
      "Section 10: 4.63%%\n",
      "Section 11: 7.06%\n",
      "Section 12: 9.23%\n",
      "Section 13: 9.38%\n",
      "Section 14: 9.20%\n",
      "Section 15: 7.50%\n",
      "Section 16: 4.43%%\n",
      "Section 17: 8.32%\n",
      "Section 18: 9.14%\n",
      "Section 19: 6.94%%\n",
      "Section 20: 3.25%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "6\t\t2551\t\t261.0\n",
      "7\t\t2694\t\t9.0\n",
      "8\t\t2596\t\t1.0\n",
      "9\t\t2621\t\t4.0\n",
      "10\t\t2310\t\t2296.0\n",
      "11\t\t3637\t\t13641.0\n",
      "12\t\t4694\t\t4297.0\n",
      "13\t\t4728\t\t16059.0\n",
      "14\t\t4785\t\t3248.0\n",
      "15\t\t3834\t\t775.0\n",
      "16\t\t2210\t\t5732.0\n",
      "17\t\t4143\t\t3253.0\n",
      "18\t\t4675\t\t1122.0\n",
      "19\t\t3574\t\t1.0\n",
      "20\t\t1647\t\tnan\n",
      "Amount Correct: 6068\n",
      "Amount Incorrect: 44631\n",
      "\n",
      "Field Section Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "6\t\t925\t\t96.0\n",
      "7\t\t878\t\t3.0\n",
      "8\t\t853\t\t3.0\n",
      "9\t\t953\t\t740.0\n",
      "10\t\t722\t\t4569.0\n",
      "11\t\t1205\t\t1493.0\n",
      "12\t\t1553\t\t5338.0\n",
      "13\t\t1489\t\t1086.0\n",
      "14\t\t1648\t\t255.0\n",
      "15\t\t1336\t\t1825.0\n",
      "16\t\t700\t\t1106.0\n",
      "17\t\t1299\t\t386.0\n",
      "18\t\t1518\t\tnan\n",
      "19\t\t1254\t\tnan\n",
      "20\t\t567\t\tnan\n",
      "Amount Correct: 1990\n",
      "Amount Incorrect: 14910\n",
      "exporting statistics to Excel...\n",
      "done!\n",
      "Training Class Splits (count, then percentage):\n",
      "[7322, 10878, 10163, 8475, 5003]\n",
      "[0.175, 0.26, 0.2429, 0.2026, 0.1196]\n",
      "\n",
      "Testing Class Splits (count, then percentage):\n",
      "[2400, 3587, 3481, 2806, 1673]\n",
      "[0.1721, 0.2572, 0.2496, 0.2012, 0.12]\n",
      "training decision tree model...\n",
      "done!\n",
      "getting statistics...\n",
      "\n",
      "logging statistics...\n",
      "printing statistics...\n",
      "Model Type: DecisionTree\n",
      "\n",
      "Training Size = 41841\n",
      "Testing Size = 13947\n",
      "\n",
      "Training Accuracy = 0.35622953562295356\n",
      "Testing Accuracy = 0.31390263139026314\n",
      "\n",
      "Training Average Error = 0.9521760952176095\n",
      "Testing Average Error = 1.00487560048756\n",
      "\n",
      "Training Recall = [0.2655012291723573, 0.5752895752895753, 0.25346846403620976, 0.33710914454277285, 0.2538476913851689]\n",
      "Testing Recall = [0.22416666666666665, 0.531642040702537, 0.19965527147371445, 0.3068424803991447, 0.22534369396294082]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.35622953562295356, 0.3367630643553824, 0.36714484320300106]\n",
      "Testing f1 (micro, macro, weighted) = [0.31390263139026314, 0.29477531239970484, 0.3262722705059189]\n",
      "\n",
      "Training auc (macro, weighted) = [0.9839452757873767, 0.9745195769996445]\n",
      "Testing auc (macro, weighted) = [0.9848572356382654, 0.9758359315204932]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Max Tree Depth: 50\n",
      "Max Tree Features: 30\n",
      "Max Leaf Nodes: 150\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 0.9522\n",
      "Accuracy Score for Predicting on Test Data: 0.3139\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 17.49%\n",
      "Section 2: 26.01%\n",
      "Section 3: 24.49%\n",
      "Section 4: 20.14%\n",
      "Section 5: 11.86%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7322\t\t5212\n",
      "2\t\t10878\t\t17964\n",
      "3\t\t10163\t\t7015\n",
      "4\t\t8475\t\t7951\n",
      "5\t\t5003\t\t3699\n",
      "Amount Correct: 14905\n",
      "Amount Incorrect: 26936\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2400\t\t1763\n",
      "2\t\t3587\t\t5960\n",
      "3\t\t3481\t\t2415\n",
      "4\t\t2806\t\t2600\n",
      "5\t\t1673\t\t1209\n",
      "Amount Correct: 4378\n",
      "Amount Incorrect: 9569\n",
      "exporting statistics to Excel...\n",
      "done!\n",
      "training Naive Bayes model...\n",
      "done!\n",
      "getting statistics...\n",
      "logging statistics...\n",
      "printing statistics...\n",
      "Model Type: NaiveBayes\n",
      "\n",
      "Training Size = 41841\n",
      "Testing Size = 13947\n",
      "\n",
      "Training Accuracy = 0.29260772926077294\n",
      "Testing Accuracy = 0.2903133290313329\n",
      "\n",
      "Training Average Error = 1.0774121077412109\n",
      "Testing Average Error = 1.0760020076002008\n",
      "\n",
      "Training Recall = [0.33870527178366566, 0.22531715388858245, 0.30010823575715834, 0.38890855457227136, 0.19308414951029382]\n",
      "Testing Recall = [0.3441666666666667, 0.22665179816002232, 0.2869864981327205, 0.3909479686386315, 0.18768679019725046]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.29260772926077294, 0.28728949738602694, 0.29613422416887397]\n",
      "Testing f1 (micro, macro, weighted) = [0.2903133290313329, 0.28489349100104466, 0.2941094686659257]\n",
      "\n",
      "Training auc (macro, weighted) = [0.980444649298537, 0.9758178694038971]\n",
      "Testing auc (macro, weighted) = [0.9805549158057986, 0.9762483417851693]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Var Smoothing: 1e-09\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 1.0774\n",
      "Accuracy Score for Predicting on Test Data: 0.2903\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 20.81%\n",
      "Section 2: 22.03%\n",
      "Section 3: 24.55%\n",
      "Section 4: 21.24%\n",
      "Section 5: 11.37%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7322\t\t8348\n",
      "2\t\t10878\t\t7692\n",
      "3\t\t10163\t\t12048\n",
      "4\t\t8475\t\t10489\n",
      "5\t\t5003\t\t3264\n",
      "Amount Correct: 12243\n",
      "Amount Incorrect: 29598\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2400\t\t2824\n",
      "2\t\t3587\t\t2599\n",
      "3\t\t3481\t\t3938\n",
      "4\t\t2806\t\t3519\n",
      "5\t\t1673\t\t1067\n",
      "Amount Correct: 4049\n",
      "Amount Incorrect: 9898\n",
      "exporting statistics to Excel...\n",
      "done!\n",
      "training logistic regression model...\n",
      "done!\n",
      "getting statistics...\n",
      "logging statistics...\n",
      "printing statistics...\n",
      "Model Type: LogisticRegression\n",
      "\n",
      "Training Size = 41841\n",
      "Testing Size = 13947\n",
      "\n",
      "Training Accuracy = 0.3288879328887933\n",
      "Testing Accuracy = 0.3296766329676633\n",
      "\n",
      "Training Average Error = 0.9489495948949594\n",
      "Testing Average Error = 0.9482325948232595\n",
      "\n",
      "Training Recall = [0.15337339524720023, 0.676594962309248, 0.07724097215389157, 0.4860176991150442, 0.0747551469118529]\n",
      "Testing Recall = [0.15666666666666668, 0.6799553944800669, 0.08532031025567366, 0.48823948681397006, 0.06933652121936641]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.3288879328887933, 0.25873948066449987, 0.3817459323619448]\n",
      "Testing f1 (micro, macro, weighted) = [0.3296766329676633, 0.26037165214881686, 0.382091089146857]\n",
      "\n",
      "Training auc (macro, weighted) = [0.9808897140551348, 0.9698220118005074]\n",
      "Testing auc (macro, weighted) = [0.9811055877877463, 0.9688988517578955]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Learning Rate: 0.8\n",
      "Epochs: 100\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 0.9489\n",
      "Accuracy Score for Predicting on Test Data: 0.3297\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 17.45%\n",
      "Section 2: 26.04%\n",
      "Section 3: 24.27%\n",
      "Section 4: 20.29%\n",
      "Section 5: 11.96%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7322\t\t2949\n",
      "2\t\t10878\t\t22339\n",
      "3\t\t10163\t\t2561\n",
      "4\t\t8475\t\t13035\n",
      "5\t\t5003\t\t957\n",
      "Amount Correct: 13761\n",
      "Amount Incorrect: 28080\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2400\t\t974\n",
      "2\t\t3587\t\t7436\n",
      "3\t\t3481\t\t887\n",
      "4\t\t2806\t\t4346\n",
      "5\t\t1673\t\t304\n",
      "Amount Correct: 4598\n",
      "Amount Incorrect: 9349\n",
      "exporting statistics to Excel...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(logs)\n",
    "importlib.reload(ModelUtil)\n",
    "# 2) Trains all Models and exports all data to an Excel Sheet\n",
    "max_depth = 50\n",
    "max_features = 30\n",
    "max_leaf_nodes = 150\n",
    "# could also add ways to change it for these hyperparams below for other models\n",
    "var_smoothing = 1e-9\n",
    "lr = 0.8\n",
    "e = 100\n",
    "rC = 1\n",
    "kernel='linear'\n",
    "degree= 1\n",
    "gamma= 'scale'\n",
    "coef0= 0.0\n",
    "xoTrain, xoTest, yoTrain, yoTest = ModelUtil.modelDataSplitting(outfieldDataFrame, 11, 0.25,'OutfieldTrainingFilter', \"Outfield\")\n",
    "print(yoTrain.head)\n",
    "OutfielddtOutput = ModelUtil.runDT(xoTrain, yoTrain, xoTest, yoTest, max_depth, max_features, max_leaf_nodes, \"Outfield\")\n",
    "OutfieldnbOutput = ModelUtil.runNB(xoTrain, yoTrain, xoTest, yoTest, var_smoothing, \"Outfield\")\n",
    "OutfieldlogRegOutput = ModelUtil.runLogReg(xoTrain, yoTrain, xoTest, yoTest, lr, e, \"Outfield\")\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, 11, 0.25,'InfieldTrainingFilter', \"Infield\")\n",
    "dtOutput = ModelUtil.runDT(xTrain, yTrain, xTest, yTest, max_depth, max_features, max_leaf_nodes, \"Infield\")\n",
    "nbOutput = ModelUtil.runNB(xTrain, yTrain, xTest, yTest, var_smoothing, \"Infield\")\n",
    "logRegOutput = ModelUtil.runLogReg(xTrain, yTrain, xTest, yTest, lr, e, \"Infield\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(logs)\n",
    "# 2) Trains all Models and exports all data to an Excel Sheet\n",
    "max_depth = 50\n",
    "max_features = 30\n",
    "max_leaf_nodes = 150\n",
    "# could also add ways to change it for these hyperparams below for other models\n",
    "var_smoothing = 1e-9\n",
    "lr = 0.8\n",
    "e = 100\n",
    "rC = 1\n",
    "kernel='linear'\n",
    "degree= 1\n",
    "gamma= 'scale'\n",
    "coef0= 0.0\n",
    "\n",
    "runCount = int(config['TRAIN']['TimesRun'])\n",
    "if (\"False\" in config['TRAIN']['Testing']):\n",
    "     runCount = 1\n",
    "     print(\"Not Testing\")\n",
    "for j in range(1, runCount+1):\n",
    "        xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, j, 0.25,'InfieldTrainingFilter')\n",
    "        if(\"True\" in config['MODELS']['DTC']):\n",
    "            dtOutput = ModelUtil.runDT(xTrain, yTrain, xTest, yTest, max_depth, max_features, max_leaf_nodes)\n",
    "            if (\"True\" in config['DATA']['Pickle']):\n",
    "                # Save the model to a file\n",
    "                with open('Models/DecisionTree.pkl', 'wb') as file:\n",
    "                  pickle.dump(dtOutput, file)\n",
    "        if(\"True\" in config['MODELS']['NB']):   \n",
    "            nbOutput = ModelUtil.runNB(xTrain, yTrain, xTest, yTest, var_smoothing)\n",
    "            if (\"True\" in config['DATA']['Pickle']):\n",
    "                # Save the model to a file\n",
    "                with open('Models/NaiveBayes.pkl', 'wb') as file:\n",
    "                  pickle.dump(nbOutput, file)\n",
    "        if(\"True\" in config['MODELS']['LR']):\n",
    "            logRegOutput = ModelUtil.runLogReg(xTrain, yTrain, xTest, yTest, lr, e)\n",
    "            if (\"True\" in config['DATA']['Pickle']):\n",
    "                # Save the model to a file\n",
    "                with open('Models/LogRegression.pkl', 'wb') as file:\n",
    "                  pickle.dump(logRegOutput, file)\n",
    "        if(\"True\" in config['MODELS']['SVM']):\n",
    "            svmOutput = ModelUtil.runSVM(xTrain, yTrain, xTest, yTest, rC, kernel, degree, gamma, coef0)\n",
    "            if (\"True\" in config['DATA']['Pickle']):\n",
    "                # Save the model to a file\n",
    "                with open('Models/SVM.pkl', 'wb') as file:\n",
    "                  pickle.dump(svmOutput, file)\n",
    "        # if(\"True\" in config['MODELS']['RF']):\n",
    "        #     for i in range(0, len(trainIn)):\n",
    "        #         direction, distance = ModelUtil.runRFR(trainIn[i], trainOut[i], testIn[i], testOut[i])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# a) Decision Tree\n",
    "# Need to test these hyperparameters for best case\n",
    "# Maybe make a way to superset these\n",
    "max_depth =      [50, 40]\n",
    "max_features =   [30, 20]\n",
    "max_leaf_nodes = [150, 100]\n",
    "hyperparamlist = []\n",
    "# This just makes the permutations of the hyperparameters above. Lets you test on many hyperparams.\n",
    "for n in range(len(max_depth)):\n",
    "    for k in range(len(max_features)):\n",
    "        for m in range(len(max_leaf_nodes)):\n",
    "            hyperparamlist.append([max_depth[n], max_features[k], max_leaf_nodes[m]])\n",
    "            \n",
    "# for each permutation, it runs a certain amount of time that you specify in the config (30 rn bc of Dozier) and saves the outcome to an excel sheet\n",
    "# requires to rerun the training set every time because otherwise will give you the same outcome every time\n",
    "# Also proves that its the models ability, not the luck of the draw for the data\n",
    "for lst in hyperparamlist:\n",
    "    runCount = int(config['TRAIN']['TimesRun'])\n",
    "    if (\"False\" in config['TRAIN']['Testing']):\n",
    "        runCount = 1\n",
    "        print(\"Not Testing\")\n",
    "    for j in range(runCount):\n",
    "        print(infieldDataFrame)\n",
    "        xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, j, 0.25,'InfieldTrainingFilter')\n",
    "        dtOutput = ModelUtil.runDT(xTrain, yTrain, xTest, yTest, lst[0], lst[1], lst[2])\n",
    "        if (\"True\" in config['DATA']['Pickle']):\n",
    "            # Save the model to a file\n",
    "            with open('Models/DecisionTree.pkl', 'wb') as file:\n",
    "                pickle.dump(dtOutput, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# b) Naive Bayes\n",
    "\n",
    "var_smoothing = 1e-9\n",
    "runCount = int(config['TRAIN']['TimesRun'])\n",
    "if (\"False\" in config['TRAIN']['Testing']):\n",
    "     runCount = 1\n",
    "     print(\"Not Testing\")\n",
    "for j in range(1, runCount+1):\n",
    "        xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, j, 0.25,'InfieldTrainingFilter')\n",
    "        nbOutput = ModelUtil.runNB(xTrain, yTrain, xTest, yTest, var_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# c)Logistic Regression\n",
    "lr = 0.8\n",
    "e = 100\n",
    "runCount = int(config['TRAIN']['TimesRun'])\n",
    "if (\"False\" in config['TRAIN']['Testing']):\n",
    "     runCount = 1\n",
    "     print(\"Not Testing\")\n",
    "for j in range(1, runCount+1):\n",
    "     xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, j, 0.25,'InfieldTrainingFilter')\n",
    "     logRegOutput = ModelUtil.runLogReg(xTrain, yTrain, xTest, yTest, lr, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# d) SVM\n",
    "rC = 1\n",
    "kernel='linear'\n",
    "degree= 1\n",
    "gamma= 'scale'\n",
    "coef0= 0.0\n",
    "runCount = int(config['TRAIN']['TimesRun'])\n",
    "if (\"False\" in config['TRAIN']['Testing']):\n",
    "     runCount = 1\n",
    "     print(\"Not Testing\")\n",
    "for j in range(1,runCount+1):\n",
    "     xTrain, xTest, yTrain, yTest = ModelUtil.modelDataSplitting(infieldDataFrame, j, 0.25,'InfieldTrainingFilter')\n",
    "     svmOutput = ModelUtil.runSVM(xTrain, yTrain, xTest, yTest, rC, kernel, degree, gamma, coef0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # z) RandomForestRegressor\n",
    "# for i in range(0, len(trainIn)):\n",
    "#     direction, distance = ModelUtil.runRFR(trainIn[i], trainOut[i], testIn[i], testOut[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# This is meant to take all the values from the 30 runs and average them and output them to another sheet of averages for different models\n",
    "# Then will need to do this for all the models\n",
    "# Can take this and put it into an excelAverages function\n",
    "#prob rename this\n",
    "\n",
    "# could move these column letter names and do something with that so not hardcoded\n",
    "if(\"True\" in config['LOGGING']['Excel']):\n",
    "    sColumns = ['Training Accuracy', 'Testing Accuracy', 'Training Average Error', 'Testing Average Error', 'Training F1(micro)', 'Training F1(macro)', 'Training F1(weighted)', \n",
    "                'Testing F1(micro)', 'Testing F1(macro)', 'Testing F1(weighted)', 'Training AUC(macro)', 'Training AUC(weighted)', 'Testing AUC(macro)', 'Testing AUC(weighted)', \n",
    "                'Section 0 Probability', 'Section 1 Probability', 'Section 2 Probability', 'Section 3 Probability', 'Section 4 Probability']\n",
    "    if(\"True\" in config['MODELS']['DTC']):\n",
    "        # columns in excel: I J K L W X Y Z AA AB AC AD AE AF AG AH AI AJ AK   \n",
    "        sColumnsLetter = ['I','J','K','L','W','X','Y','Z','AA','AB','AC','AD','AE','AF','AG','AH','AI','AJ','AK']\n",
    "        logs.excelAverages('DecisionTree',sColumns,sColumnsLetter)\n",
    "    if(\"True\" in config['MODELS']['NB']):\n",
    "        sColumnsLetter = ['D','E','F','G','R','S','T','U','V','W','X','Y','Z','AA','AB','AC','AD','AE','AF']\n",
    "        logs.excelAverages('NaiveBayes',sColumns,sColumnsLetter)\n",
    "    if(\"True\" in config['MODELS']['LR']):\n",
    "        sColumnsLetter = ['E','F','G','H','S','T','U','V','W','X','Y','Z','AA','AB','AC','AD','AE','AF','AG']\n",
    "        logs.excelAverages('LogisticRegression',sColumns,sColumnsLetter)\n",
    "    if(\"True\" in config['MODELS']['SVM']):\n",
    "        sColumnsLetter = ['H','I','J','K','V','W','X','Y','Z','AA','AB','AC','AD','AE','AF','AG','AH','AI','AJ']\n",
    "        logs.excelAverages('SVM',sColumns,sColumnsLetter)\n",
    "    if(\"True\" in config['MODELS']['RF']):\n",
    "        logs.excelAverages('RandomForest',sColumns,sColumnsLetter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the value of index to look at different datapoints\n",
    "importlib.reload(VisualUtil)\n",
    "# 3) Model Testing:\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "\n",
    "print(\"Testing Output: \")\n",
    "# index of test value:\n",
    "index = 4555\n",
    "print(f\"Actual Field Slice: \\t\\t{yTest.iloc[index]}\")\n",
    "\n",
    "print(\"\\nDecision Tree:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{dt.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{dt.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "print(\"\\nNaive Bayes:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{nb.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{nb.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{logReg.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{logReg.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "# print(\"\\nSVM:\")\n",
    "# print(f\"Predicted Field Slice: \\t\\t{svm.predict([xTest.iloc[index]])[0]}\")\n",
    "# print(f\"Field Slice Probabilities: \\t{svm.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "averageProbs = dt.predict_proba([xTest.iloc[index]])[0] + nb.predict_proba([xTest.iloc[index]])[0] + logReg.predict_proba([xTest.iloc[index]])[0] # + svm.predict_proba([xTest.iloc[index]])[0]\n",
    "averageProbs = averageProbs / 3 \n",
    "\n",
    "print(f\"\\n\\nAVG Prediction: \\t\\t{np.argmax(averageProbs)+1}\")\n",
    "print(f\"Field Slice AVG Probabilities: \\t{averageProbs}\")\n",
    "\n",
    "VisualUtil.visualizeData(averageProbs, [1], 'TestPic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Data Visualization\n",
    "importlib.reload(VisualUtil)\n",
    "\n",
    "# Temporary method of getting percentages for testing purposes\n",
    "infieldPercentages  = np.random.dirichlet(np.ones(5), size=1)[0]\n",
    "outfieldPercentages = np.random.dirichlet(np.ones(2), size=1)[0]\n",
    "outfieldCoordinates = np.random.uniform(low=[-45, 150], high=[45, 400], size=(30,2))\n",
    "\n",
    "outfieldCoordinates = [0,1,0,0,3,0,0,0,0,0,0,0,0,5,0]\n",
    "VisualUtil.visualizeData(infieldPercentages, outfieldCoordinates, \"FieldTest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [0,1,2,3]\n",
    "o = [2,3,4,5]\n",
    "\n",
    "print(l+o)\n",
    "l.append(o)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Pitcher Data Processing and Running\n",
    "importlib.reload(Preprocessing)\n",
    "importlib.reload(DataUtil)\n",
    "importlib.reload(VisualUtil)\n",
    "importlib.reload(batch_image_to_excel)\n",
    "importlib.reload(logs)\n",
    "\n",
    "\n",
    "pitchingAveragesDF = DataUtil.getRawDataFrame('Data/PitchMetricAverages_AsOf_2024-03-11.csv', [])\n",
    "# drop nan values from the used columns\n",
    "specific_columns = [\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"RelSpeed\", \"InducedVertBreak\", \"HorzBreak\", \"RelHeight\", \"RelSide\", \"SpinAxis\", \"SpinRate\", \"VertApprAngle\", \"HorzApprAngle\"] # pitcher averages\n",
    "infieldDataFrame = infieldDataFrame[specific_columns] \n",
    "outfieldDataFrame = outfieldDataFrame[specific_columns]\n",
    "averagesX = pitchingAveragesDF[specific_columns] # pitcher averages\n",
    "#averagesX = averagesX.dropna(axis=0, how='any',subset=specific_columns)\n",
    "#averagesX = averagesX[[\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"PlateLocHeight\", \"PlateLocSide\", \"ZoneSpeed\", \"RelSpeed\", \"SpinRate\", \"HorzBreak\", \"VertBreak\"]]\n",
    "\n",
    "averagesX[\"PitcherThrows\"] = averagesX[\"PitcherThrows\"].map({\"Left\":1, \"Right\":2, \"Both\":3})\n",
    "averagesX[\"BatterSide\"] = averagesX[\"BatterSide\"].map({\"Left\":1, \"Right\":2})\n",
    "averagesX[\"TaggedPitchType\"] = averagesX[\"TaggedPitchType\"].map({\"Fastball\": 1, \"FourSeamFastBall\":1, \"Sinker\":2, \"TwoSeamFastBall\":2, \"Cutter\":3, \"Curveball\":4, \"Slider\":5, \"ChangeUp\":6, \"Splitter\":7, \"Knuckleball\":8})\n",
    "\n",
    "# normalize this based on min and maxes from training data\n",
    "averagesX = DataUtil.normalizeData(averagesX, infieldDataFrame)\n",
    "\n",
    "# Change the value of index to look at different datapoints\n",
    "importlib.reload(VisualUtil)\n",
    "# 3) Model Testing:\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "dto = OutfielddtOutput[0]\n",
    "nbo = OutfieldnbOutput[0]\n",
    "logRego = OutfieldlogRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "for index in range(pitchingAveragesDF.shape[0]):\n",
    "    #print(index)\n",
    "    averageProbs= []\n",
    "    averageProbs = dt.predict_proba([averagesX.iloc[index]])[0] + nb.predict_proba([averagesX.iloc[index]])[0] + logReg.predict_proba([averagesX.iloc[index]])[0]\n",
    "    averageProbs = averageProbs / 3 \n",
    "\n",
    "    averageProbso= []\n",
    "    averageProbso = dto.predict_proba([averagesX.iloc[index]])[0] + nbo.predict_proba([averagesX.iloc[index]])[0] + logRego.predict_proba([averagesX.iloc[index]])[0]\n",
    "    averageProbso = averageProbso / 3 \n",
    "\n",
    "    # print(f\"\\n\\nAVG Prediction: \\t\\t{np.argmax(averageProbs)+1}\")\n",
    "    # print(f\"Field Slice AVG Probabilities: \\t{averageProbs}\")\n",
    "    fileName = pitchingAveragesDF.iloc[index][0].replace(\",\", \"_\").replace(\" \", \"\") + \"_\" + pitchingAveragesDF.iloc[index][\"TaggedPitchType\"] + \"_\" + pitchingAveragesDF.iloc[index][\"BatterSide\"] + \"Batter\"\n",
    "    VisualUtil.visualizeData(averageProbs, averageProbso, fileName)   \n",
    "\n",
    "batch_image_to_excel.create_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Pitcher Data Processing and Running\n",
    "importlib.reload(Preprocessing)\n",
    "importlib.reload(DataUtil)\n",
    "importlib.reload(VisualUtil)\n",
    "importlib.reload(batch_image_to_excel)\n",
    "import math\n",
    "\n",
    "\n",
    "pitchingAveragesDF = DataUtil.getRawDataFrame('Data/PitchMetricAverages_AsOf_2024-03-11.csv', [])\n",
    "# drop nan values from the used columns\n",
    "specific_columns = [\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"RelSpeed\", \"InducedVertBreak\", \"HorzBreak\", \"RelHeight\", \"RelSide\", \"SpinAxis\", \"SpinRate\", \"VertApprAngle\", \"HorzApprAngle\"]#, \"Extension\"] # pitcher averages\n",
    "outfieldDataFrame = outfieldDataFrame[specific_columns] \n",
    "infieldDataFrame = infieldDataFrame[specific_columns]\n",
    "averagesX = pitchingAveragesDF[specific_columns] # pitcher averages\n",
    "#averagesX = averagesX[[\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"PlateLocHeight\", \"PlateLocSide\", \"ZoneSpeed\", \"RelSpeed\", \"SpinRate\", \"HorzBreak\", \"VertBreak\"]]\n",
    "averagesX[\"PitcherThrows\"] = averagesX[\"PitcherThrows\"].map({\"Left\":1, \"Right\":2, \"Both\":3})\n",
    "averagesX[\"BatterSide\"] = averagesX[\"BatterSide\"].map({\"Left\":1, \"Right\":2})\n",
    "averagesX[\"TaggedPitchType\"] = averagesX[\"TaggedPitchType\"].map({\"Fastball\": 1, \"FourSeamFastBall\":1, \"Sinker\":2, \"TwoSeamFastBall\":2, \"Cutter\":3, \"Curveball\":4, \"Slider\":5, \"ChangeUp\":6, \"Splitter\":7, \"Knuckleball\":8})\n",
    "\n",
    "# normalize this based on min and maxes from training data\n",
    "averagesX = DataUtil.normalizeData(averagesX, infieldDataFrame)\n",
    "\n",
    "# Change the value of index to look at different datapoints\n",
    "importlib.reload(VisualUtil)\n",
    "# 3) Model Testing:\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "\n",
    "dto = OutfielddtOutput[0]\n",
    "nbo = OutfieldnbOutput[0]\n",
    "logRego = OutfieldlogRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "for index in range(pitchingAveragesDF.shape[0]):\n",
    "    #print(index)\n",
    "    averageProbs= []\n",
    "    averageProbs = dt.predict_proba([averagesX.iloc[index]])[0] + nb.predict_proba([averagesX.iloc[index]])[0] + logReg.predict_proba([averagesX.iloc[index]])[0]\n",
    "    averageProbs = averageProbs / 3 \n",
    "\n",
    "    averageProbso= []\n",
    "    averageProbso = dto.predict_proba([averagesX.iloc[index]])[0] + nbo.predict_proba([averagesX.iloc[index]])[0] + logRego.predict_proba([averagesX.iloc[index]])[0]\n",
    "    averageProbso = averageProbso / 3 \n",
    "\n",
    "    # print(f\"\\n\\nAVG Prediction: \\t\\t{np.argmax(averageProbs)+1}\")\n",
    "    # print(f\"Field Slice AVG Probabilities: \\t{averageProbs}\")\n",
    "    fileName = pitchingAveragesDF.iloc[index][0].replace(\",\", \"_\").replace(\" \", \"\") + \"_\" + pitchingAveragesDF.iloc[index][\"TaggedPitchType\"] + \"_\" + pitchingAveragesDF.iloc[index][\"BatterSide\"] + \"Batter\"\n",
    "    VisualUtil.visualizeData(averageProbs, averageProbso, fileName)   \n",
    "\n",
    "batch_image_to_excel.create_excel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
