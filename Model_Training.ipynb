{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training:\n",
    "# 1) Load all data from preprocessing (training/test splits, etc)\n",
    "# 2) Begin Training Models\n",
    "    #  a) Decision Tree\n",
    "    #  b) Naive Bayes\n",
    "    #  c) Logistic Regression\n",
    "    #  d) SVM\n",
    "# 3) Testing Models\n",
    "# 4) New Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from Models import ModelUtil\n",
    "from Data import Preprocessing, DataUtil\n",
    "from Visualization import VisualUtil\n",
    "from Logs import logging as logs\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import configparser\n",
    "import numpy as np\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('Data//config.ini')\n",
    "\n",
    "importlib.reload(Preprocessing)\n",
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(VisualUtil)\n",
    "importlib.reload(logs)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load all data from preprocessing \n",
    "importlib.reload(Preprocessing)\n",
    "\n",
    "if(\"False\" in config['DATA']['USE_NEW_PREPROCESSING']):\n",
    "    infieldDataFrame, outfieldDataFrame = Preprocessing.dataFiltering([], False)\n",
    "\n",
    "    # drop nan values from the used columns\n",
    "    specific_columns = [\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"PlateLocHeight\", \"PlateLocSide\", \"ZoneSpeed\", \"SpinRate\", \"RelSpeed\", \"HorzBreak\", \"VertBreak\"]\n",
    "    specific_columns = [\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"RelSpeed\", \"VertRelAngle\", \"HorzRelAngle\", \"SpinRate\", \"SpinAxis\", \"RelHeight\", \"RelSide\", \"VertBreak\", \"InducedVertBreak\", \"HorzBreak\", \"VertApprAngle\", \"HorzApprAngle\"] # pitcher averages\n",
    "    specific_columns = [\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"RelSpeed\", \"InducedVertBreak\", \"HorzBreak\", \"RelHeight\", \"RelSide\", \"SpinAxis\", \"SpinRate\", \"VertApprAngle\", \"HorzApprAngle\"] \n",
    "    infieldDataFrame = infieldDataFrame.dropna(axis=0, how='any',subset=specific_columns)\n",
    "\n",
    "else:\n",
    "    normDataFrame = Preprocessing.dataProcessing()\n",
    "    infieldDataFrame, outfieldDataFrame = Preprocessing.dataFiltering(normDataFrame, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infieldcorrmatrix = infieldDataFrame.corr()\n",
    "infieldcorrmatrix.to_csv('Infield_Correlation_Matrix')\n",
    "outfieldcorrmatrix = outfieldDataFrame.corr()\n",
    "outfieldcorrmatrix.to_csv('Outfield_Correlation_Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Class Splits (count, then percentage):\n",
      "[7280, 10890, 10257, 8471, 4956]\n",
      "[0.1739, 0.2602, 0.2451, 0.2024, 0.1184]\n",
      "\n",
      "Testing Class Splits (count, then percentage):\n",
      "[2444, 3583, 3391, 2813, 1721]\n",
      "[0.1752, 0.2568, 0.243, 0.2016, 0.1234]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(Preprocessing)\n",
    "importlib.reload(DataUtil)\n",
    "\n",
    "if(\"False\" in config['DATA']['USE_NEW_PREPROCESSING']):\n",
    "    Y = infieldDataFrame[\"FieldSlice\"]\n",
    "    X = infieldDataFrame[[\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"PlateLocHeight\", \"PlateLocSide\", \"ZoneSpeed\", \"SpinRate\", \"RelSpeed\", \"HorzBreak\", \"VertBreak\"]] \n",
    "    X = infieldDataFrame[specific_columns] # pitcher averages\n",
    "    originalNotNormX = X\n",
    "    X = DataUtil.normalizeData(X, originalNotNormX)\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.25, random_state=11)\n",
    "    # adb = AdaBoostClassifier()\n",
    "    # adb_model = adb.fit(xTrain, yTrain)\n",
    "\n",
    "    # calculate split information:\n",
    "    trainingClassSplit = [0, 0, 0, 0, 0]\n",
    "    for i in yTrain:\n",
    "        trainingClassSplit[i-1] += 1\n",
    "\n",
    "    \n",
    "    testingClassSplit = [0, 0, 0, 0, 0]\n",
    "    for i in yTest:\n",
    "        testingClassSplit[i-1] += 1\n",
    "\n",
    "    trainingClassPercent = []\n",
    "    for i in trainingClassSplit:\n",
    "        trainingClassPercent.append(round(i/len(yTrain), 4))\n",
    "\n",
    "    testingClassPercent = []\n",
    "    for i in testingClassSplit:\n",
    "        testingClassPercent.append(round(i/len(yTest), 4))\n",
    "\n",
    "    print(\"Training Class Splits (count, then percentage):\")\n",
    "    print(trainingClassSplit)\n",
    "    print(trainingClassPercent)\n",
    "    print(\"\\nTesting Class Splits (count, then percentage):\")\n",
    "    print(testingClassSplit)\n",
    "    print(testingClassPercent)\n",
    "else:\n",
    "    infieldY = infieldDataFrame[0][['Direction','Distance']]\n",
    "    infieldX = infieldDataFrame[0][infieldDataFrame[1]] \n",
    "    if(\"True\" in config['SPLIT']['TTS']):\n",
    "        xTrain, xTest, yTrain, yTest = train_test_split(infieldX, infieldY, test_size=0.20, random_state=11)\n",
    "        \n",
    "    elif(\"True\" in config['SPLIT']['KFold']):\n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "        for train_index, test_index in kf.split(infieldX):\n",
    "            xTrain, xTest = infieldX.iloc[train_index,:], infieldX.iloc[test_index,:]\n",
    "            yTrain, yTest = infieldY.iloc[train_index,:], infieldY.iloc[test_index,:]\n",
    "\n",
    "    elif(\"True\" in config['SPLIT']['LOOCV']):\n",
    "        loo = LeaveOneOut()\n",
    "        for train_index, test_index in loo.split(infieldX):\n",
    "            xTrain, xTest = infieldX.iloc[train_index,:], infieldX.iloc[test_index,:]\n",
    "            yTrain, yTest = infieldY.iloc[train_index,:], infieldY.iloc[test_index,:]\n",
    "\n",
    "    else:\n",
    "        print(\"No Splitting Method Selected\")\n",
    "        \n",
    "\n",
    "# GroupKFold: (avoids putting data from the same group in the test set -- useful for Pitcher/Batter ID when we implement that.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training decision tree model...\n",
      "done!\n",
      "getting statistics...\n",
      "\n",
      "printing statistics...\n",
      "Model Type: DecisionTree\n",
      "\n",
      "Training Size = 41854\n",
      "Testing Size = 13952\n",
      "\n",
      "Training Accuracy = 0.35301285420748313\n",
      "Testing Accuracy = 0.310134747706422\n",
      "\n",
      "Training Average Error = 0.9330768863191092\n",
      "Testing Average Error = 0.9924025229357798\n",
      "\n",
      "Training Recall = [0.24684065934065935, 0.5972451790633608, 0.26050502096129474, 0.377523314838862, 0.12187247780468119]\n",
      "Testing Recall = [0.2311783960720131, 0.5428411945297237, 0.22087879681509878, 0.3238535371489513, 0.09122603137710633]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.35301285420748313, 0.3169975897911577, 0.3711977042646309]\n",
      "Testing f1 (micro, macro, weighted) = [0.310134747706422, 0.27553187540417035, 0.3283299900671702]\n",
      "\n",
      "Training auc (macro, weighted) = [0.9831208645285029, 0.9794745302320497]\n",
      "Testing auc (macro, weighted) = [0.9836491352523176, 0.9797677630983791]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Max Tree Depth: 50\n",
      "Max Tree Features: 30\n",
      "Max Leaf Nodes: 150\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 0.9331\n",
      "Accuracy Score for Predicting on Test Data: 0.3101\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 17.38%\n",
      "Section 2: 25.93%\n",
      "Section 3: 24.53%\n",
      "Section 4: 20.24%\n",
      "Section 5: 11.93%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7280\t\t4963\n",
      "2\t\t10890\t\t18895\n",
      "3\t\t10257\t\t7718\n",
      "4\t\t8471\t\t8705\n",
      "5\t\t4956\t\t1573\n",
      "Amount Correct: 14775\n",
      "Amount Incorrect: 27079\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2444\t\t1706\n",
      "2\t\t3583\t\t6197\n",
      "3\t\t3391\t\t2617\n",
      "4\t\t2813\t\t2899\n",
      "5\t\t1721\t\t533\n",
      "Amount Correct: 4327\n",
      "Amount Incorrect: 9625\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# a) Decision Tree\n",
    "# Need to test these hyperparameters for best case\n",
    "max_depth = 50\n",
    "max_features = 30\n",
    "max_leaf_nodes = 150\n",
    "dtOutput = ModelUtil.runDT(xTrain, yTrain, xTest, yTest, max_depth, max_features, max_leaf_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Naive Bayes model...\n",
      "done!\n",
      "getting statistics...\n",
      "printing statistics...\n",
      "Model Type: NaiveBayes\n",
      "\n",
      "Training Size = 41854\n",
      "Testing Size = 13952\n",
      "\n",
      "Training Accuracy = 0.29825106321976397\n",
      "Testing Accuracy = 0.2993836009174312\n",
      "\n",
      "Training Average Error = 1.07201223300043\n",
      "Testing Average Error = 1.0707425458715596\n",
      "\n",
      "Training Recall = [0.3423076923076923, 0.3335169880624426, 0.2043482499756264, 0.3952307873922795, 0.18462469733656175]\n",
      "Testing Recall = [0.3355155482815057, 0.32989115266536423, 0.21439103509289295, 0.3903306078919303, 0.20337013364323067]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.29825106321976397, 0.28910707130782465, 0.30332729041691026]\n",
      "Testing f1 (micro, macro, weighted) = [0.2993836009174312, 0.29335265563622887, 0.303461160114694]\n",
      "\n",
      "Training auc (macro, weighted) = [0.9817572684001687, 0.9795056791054704]\n",
      "Testing auc (macro, weighted) = [0.9825934785773457, 0.9801966947889239]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Var Smoothing: 1e-09\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 1.0720\n",
      "Accuracy Score for Predicting on Test Data: 0.2994\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 20.57%\n",
      "Section 2: 22.28%\n",
      "Section 3: 24.20%\n",
      "Section 4: 21.50%\n",
      "Section 5: 11.46%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7280\t\t8489\n",
      "2\t\t10890\t\t11365\n",
      "3\t\t10257\t\t8205\n",
      "4\t\t8471\t\t10642\n",
      "5\t\t4956\t\t3153\n",
      "Amount Correct: 12483\n",
      "Amount Incorrect: 29371\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2444\t\t2739\n",
      "2\t\t3583\t\t3813\n",
      "3\t\t3391\t\t2784\n",
      "4\t\t2813\t\t3520\n",
      "5\t\t1721\t\t1096\n",
      "Amount Correct: 4177\n",
      "Amount Incorrect: 9775\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# b) Naive Bayes\n",
    "\n",
    "var_smoothing = 1e-9\n",
    "nbOutput = ModelUtil.runNB(xTrain, yTrain, xTest, yTest, var_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training logistic regression model...\n",
      "done!\n",
      "getting statistics...\n",
      "printing statistics...\n",
      "Model Type: LogisticRegression\n",
      "\n",
      "Training Size = 41854\n",
      "Testing Size = 13952\n",
      "\n",
      "Training Accuracy = 0.3293353084531944\n",
      "Testing Accuracy = 0.3268348623853211\n",
      "\n",
      "Training Average Error = 0.9563243656520285\n",
      "Testing Average Error = 0.9610808486238532\n",
      "\n",
      "Training Recall = [0.184478021978022, 0.6742883379247016, 0.06532124402846837, 0.48424034942745836, 0.06577885391444714]\n",
      "Testing Recall = [0.19435351882160393, 0.6673178900362824, 0.07225007372456503, 0.4735158194098827, 0.06798373038930854]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.3293353084531944, 0.2586348017297306, 0.383197598780785]\n",
      "Testing f1 (micro, macro, weighted) = [0.3268348623853211, 0.2611152772127467, 0.37754840943466816]\n",
      "\n",
      "Training auc (macro, weighted) = [0.97406089044567, 0.9642570057914913]\n",
      "Testing auc (macro, weighted) = [0.9727640219584959, 0.9634473797473708]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Learning Rate: 0.8\n",
      "Epochs: 100\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 0.9563\n",
      "Accuracy Score for Predicting on Test Data: 0.3268\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 17.35%\n",
      "Section 2: 25.95%\n",
      "Section 3: 24.52%\n",
      "Section 4: 20.32%\n",
      "Section 5: 11.86%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7280\t\t3607\n",
      "2\t\t10890\t\t22278\n",
      "3\t\t10257\t\t2231\n",
      "4\t\t8471\t\t12873\n",
      "5\t\t4956\t\t865\n",
      "Amount Correct: 13784\n",
      "Amount Incorrect: 28070\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2444\t\t1190\n",
      "2\t\t3583\t\t7418\n",
      "3\t\t3391\t\t771\n",
      "4\t\t2813\t\t4273\n",
      "5\t\t1721\t\t300\n",
      "Amount Correct: 4560\n",
      "Amount Incorrect: 9392\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# c)Logistic Regression\n",
    "lr = 0.8\n",
    "e = 100\n",
    "logRegOutput = ModelUtil.runLogReg(xTrain, yTrain, xTest, yTest, lr, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM model...\n",
      "done!\n",
      "getting statistics...\n",
      "logging statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:71: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats = dftest.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:75: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:77: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats = dftrain.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:81: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing statistics...\n",
      "Model Type: SVM\n",
      "\n",
      "Training Size = 42213\n",
      "Testing Size = 14072\n",
      "\n",
      "Training Accuracy = 0.31333949257337784\n",
      "Testing Accuracy = 0.32227117680500283\n",
      "\n",
      "Training Average Error = 0.9562220169142207\n",
      "Testing Average Error = 0.9404491188175099\n",
      "\n",
      "Training Recall = [0.0, 0.8033190480532506, 0.0, 0.5206884356949193, 0.0]\n",
      "Testing Recall = [0.0, 0.8188306340927807, 0.0, 0.5387018396390142, 0.0]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.31333949257337784, 0.16828958750340162, 0.43098074084009164]\n",
      "Testing f1 (micro, macro, weighted) = [0.32227117680500283, 0.17354902523824683, 0.44205483936829404]\n",
      "\n",
      "Training auc (macro, weighted) = Error\n",
      "Testing auc (macro, weighted) = Error\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Regularization Constant: 1\n",
      "Kernel Type: linear\n",
      "Kernel Degree1\n",
      "Kernel Coefficient (gamma): scale\n",
      "Independent Term in Kernel (coef0): 0.0\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 0.9562\n",
      "Accuracy Score for Predicting on Test Data: 0.3223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:172: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats = dftest.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:176: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:178: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats = dftrain.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:182: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 16.61%\n",
      "Section 2: 26.53%\n",
      "Section 3: 25.04%\n",
      "Section 4: 20.27%\n",
      "Section 5: 11.55%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7295\t\t28007.0\n",
      "2\t\t10967\t\t14206.0\n",
      "3\t\t10348\t\tnan\n",
      "4\t\t8483\t\tnan\n",
      "5\t\t5120\t\tnan\n",
      "Amount Correct: 13227\n",
      "Amount Incorrect: 28986\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2513\t\t9367.0\n",
      "2\t\t3643\t\t4705.0\n",
      "3\t\t3427\t\tnan\n",
      "4\t\t2881\t\tnan\n",
      "5\t\t1608\t\tnan\n",
      "Amount Correct: 4535\n",
      "Amount Incorrect: 9537\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# d) SVM\n",
    "rC = 1\n",
    "kernel='linear'\n",
    "degree= 1\n",
    "gamma= 'scale'\n",
    "coef0= 0.0\n",
    "svmOutput = ModelUtil.runSVM(xTrain, yTrain, xTest, yTest, rC, kernel, degree, gamma, coef0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z) RandomForestRegressor\n",
    "for i in range(0, len(trainIn)):\n",
    "    direction, distance = ModelUtil.runRFR(trainIn[i], trainOut[i], testIn[i], testOut[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Output: \n",
      "Actual Field Slice: \t\t4\n",
      "\n",
      "Decision Tree:\n",
      "Predicted Field Slice: \t\t3\n",
      "Field Slice Probabilities: \t[0.09431138 0.26047904 0.36227545 0.19610778 0.08682635]\n",
      "\n",
      "Naive Bayes:\n",
      "Predicted Field Slice: \t\t4\n",
      "Field Slice Probabilities: \t[0.00630868 0.09324774 0.32466916 0.37936206 0.19641235]\n",
      "\n",
      "Logistic Regression:\n",
      "Predicted Field Slice: \t\t4\n",
      "Field Slice Probabilities: \t[0.0300238  0.1356919  0.26967401 0.33883047 0.22577982]\n",
      "\n",
      "\n",
      "AVG Prediction: \t\t3\n",
      "Field Slice AVG Probabilities: \t[0.04354795 0.16313956 0.31887287 0.30476677 0.16967284]\n"
     ]
    }
   ],
   "source": [
    "# Change the value of index to look at different datapoints\n",
    "importlib.reload(VisualUtil)\n",
    "# 3) Model Testing:\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "\n",
    "print(\"Testing Output: \")\n",
    "# index of test value:\n",
    "index = 4555\n",
    "print(f\"Actual Field Slice: \\t\\t{yTest.iloc[index]}\")\n",
    "\n",
    "print(\"\\nDecision Tree:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{dt.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{dt.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "print(\"\\nNaive Bayes:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{nb.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{nb.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{logReg.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{logReg.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "# print(\"\\nSVM:\")\n",
    "# print(f\"Predicted Field Slice: \\t\\t{svm.predict([xTest.iloc[index]])[0]}\")\n",
    "# print(f\"Field Slice Probabilities: \\t{svm.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "averageProbs = dt.predict_proba([xTest.iloc[index]])[0] + nb.predict_proba([xTest.iloc[index]])[0] + logReg.predict_proba([xTest.iloc[index]])[0] # + svm.predict_proba([xTest.iloc[index]])[0]\n",
    "averageProbs = averageProbs / 3 \n",
    "\n",
    "print(f\"\\n\\nAVG Prediction: \\t\\t{np.argmax(averageProbs)+1}\")\n",
    "print(f\"Field Slice AVG Probabilities: \\t{averageProbs}\")\n",
    "\n",
    "VisualUtil.visualizeData(averageProbs, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4392\n",
      "9560\n",
      "0.20483854131525492\n",
      "1.490376569037657\n"
     ]
    }
   ],
   "source": [
    "# Gather data on average predictions\n",
    "length = len(xTest)\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "wrongProbs = 0\n",
    "wrongDistance = 0\n",
    "\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "for index in range(length):\n",
    "    averageProbs = dt.predict_proba([xTest.iloc[index]])[0] + nb.predict_proba([xTest.iloc[index]])[0] + logReg.predict_proba([xTest.iloc[index]])[0] #+ svm.predict_proba([xTest.iloc[index]])[0]\n",
    "    averageProbs = averageProbs / 3\n",
    "\n",
    "    actual = yTest.iloc[index]\n",
    "    predicted = np.argmax(averageProbs)+1\n",
    "\n",
    "    percentageActual = averageProbs[actual-1]\n",
    "\n",
    "    if predicted == actual:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1 \n",
    "        wrongProbs += percentageActual\n",
    "        wrongDistance += abs(actual-predicted)\n",
    "\n",
    "\n",
    "# Correct Prediction Count\n",
    "print(correct)\n",
    "# Incorrect Prediction Count\n",
    "print(incorrect)\n",
    "# Average probability of actual slice when guess is incorrect\n",
    "print(wrongProbs/incorrect)\n",
    "# Average distance from actual slice to guess slice when guess is incorrect\n",
    "print(wrongDistance/incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Model Iterations and Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Data Visualization\n",
    "importlib.reload(VisualUtil)\n",
    "\n",
    "# Temporary method of getting percentages for testing purposes\n",
    "infieldPercentages  = np.random.dirichlet(np.ones(4), size=1)[0]\n",
    "outfieldPercentages = np.random.dirichlet(np.ones(2), size=1)[0]\n",
    "\n",
    "VisualUtil.visualizeData(infieldPercentages, outfieldPercentages, \"FieldTest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "DecompressionBombError",
     "evalue": "Image size (220478360 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDecompressionBombError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# print(f\"\\n\\nAVG Prediction: \\t\\t{np.argmax(averageProbs)+1}\")\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# print(f\"Field Slice AVG Probabilities: \\t{averageProbs}\")\u001b[39;00m\n\u001b[0;32m     36\u001b[0m fileName \u001b[38;5;241m=\u001b[39m pitchingAveragesDF\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m pitchingAveragesDF\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaggedPitchType\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m pitchingAveragesDF\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatterSide\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 37\u001b[0m \u001b[43mVisualUtil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualizeData\u001b[49m\u001b[43m(\u001b[49m\u001b[43maverageProbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileName\u001b[49m\u001b[43m)\u001b[49m   \n",
      "File \u001b[1;32mc:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Visualization\\VisualUtil.py:53\u001b[0m, in \u001b[0;36mvisualizeData\u001b[1;34m(infieldPercentages, outfieldPercentages, filename)\u001b[0m\n\u001b[0;32m     50\u001b[0m surface\u001b[38;5;241m.\u001b[39mwrite_to_png(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVisualization/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Write text on top of the image\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVisualization/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVISUAL\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRenderOutfield\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     55\u001b[0m     image \u001b[38;5;241m=\u001b[39m addPercents(image, infield_slices,  infieldPercentages,  DISTANCE_TO_GRASS)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3259\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3256\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   3257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3259\u001b[0m im \u001b[38;5;241m=\u001b[39m \u001b[43m_open_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m formats \u001b[38;5;129;01mis\u001b[39;00m ID:\n\u001b[0;32m   3262\u001b[0m     checked_formats \u001b[38;5;241m=\u001b[39m formats\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3246\u001b[0m, in \u001b[0;36mopen.<locals>._open_core\u001b[1;34m(fp, filename, prefix, formats)\u001b[0m\n\u001b[0;32m   3244\u001b[0m         fp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   3245\u001b[0m         im \u001b[38;5;241m=\u001b[39m factory(fp, filename)\n\u001b[1;32m-> 3246\u001b[0m         \u001b[43m_decompression_bomb_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3247\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m im\n\u001b[0;32m   3248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSyntaxError\u001b[39;00m, \u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, struct\u001b[38;5;241m.\u001b[39merror):\n\u001b[0;32m   3249\u001b[0m     \u001b[38;5;66;03m# Leave disabled by default, spams the logs with image\u001b[39;00m\n\u001b[0;32m   3250\u001b[0m     \u001b[38;5;66;03m# opening failures that are entirely expected.\u001b[39;00m\n\u001b[0;32m   3251\u001b[0m     \u001b[38;5;66;03m# logger.debug(\"\", exc_info=True)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3154\u001b[0m, in \u001b[0;36m_decompression_bomb_check\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   3149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pixels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m MAX_IMAGE_PIXELS:\n\u001b[0;32m   3150\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   3151\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpixels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pixels) exceeds limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m2\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mMAX_IMAGE_PIXELS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixels, could be decompression bomb DOS attack.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3153\u001b[0m     )\n\u001b[1;32m-> 3154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DecompressionBombError(msg)\n\u001b[0;32m   3156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pixels \u001b[38;5;241m>\u001b[39m MAX_IMAGE_PIXELS:\n\u001b[0;32m   3157\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   3158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpixels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pixels) exceeds limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAX_IMAGE_PIXELS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pixels, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould be decompression bomb DOS attack.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3160\u001b[0m         DecompressionBombWarning,\n\u001b[0;32m   3161\u001b[0m     )\n",
      "\u001b[1;31mDecompressionBombError\u001b[0m: Image size (220478360 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack."
     ]
    }
   ],
   "source": [
    "# Average Pitcher Data Processing and Running\n",
    "importlib.reload(Preprocessing)\n",
    "importlib.reload(DataUtil)\n",
    "\n",
    "pitchingAveragesDF = DataUtil.getRawDataFrame('Data/PitchMetricAverages_AsOf_2024-03-11.csv')\n",
    "\n",
    "# drop nan values from the used columns\n",
    "specific_columns = [\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"RelSpeed\", \"InducedVertBreak\", \"HorzBreak\", \"RelHeight\", \"RelSide\", \"SpinAxis\", \"SpinRate\", \"VertApprAngle\", \"HorzApprAngle\"] # pitcher averages\n",
    "\n",
    "averagesX = pitchingAveragesDF[specific_columns] # pitcher averages\n",
    "\n",
    "averagesX = averagesX[averagesX[\"PitcherThrows\"].isin([\"Left\", \"Right\", \"Both\"])] # 1, 2, 3 (can remove Both)\n",
    "averagesX[\"PitcherThrows\"] = averagesX[\"PitcherThrows\"].map({\"Left\":1, \"Right\":2, \"Both\":3})\n",
    "averagesX = averagesX[averagesX[\"BatterSide\"].isin([\"Left\",\"Right\"])] # 1, 2\n",
    "averagesX[\"BatterSide\"] = averagesX[\"BatterSide\"].map({\"Left\":1, \"Right\":2})\n",
    "averagesX = averagesX[averagesX[\"TaggedPitchType\"].isin([\"Fastball\", \"Sinker\", \"Cutter\", \"Curveball\", \"Slider\", \"Changeup\", \"Splitter\", \"Knuckleball\"])] # 1,2,3,4,5,6,7,8\n",
    "averagesX[\"TaggedPitchType\"] = averagesX[\"TaggedPitchType\"].map({\"Fastball\":1, \"Sinker\":2, \"Cutter\":3, \"Curveball\":4, \"Slider\":5, \"Changeup\":6, \"Splitter\":7, \"Knuckleball\":8})\n",
    "# normalize this based on min and maxes from training data\n",
    "averagesX = DataUtil.normalizeData(averagesX, originalNotNormX)\n",
    "\n",
    "# Change the value of index to look at different datapoints\n",
    "importlib.reload(VisualUtil)\n",
    "# 3) Model Testing:\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "\n",
    "for index in range(len(pitchingAveragesDF)):\n",
    "    averageProbs= []\n",
    "    averageProbs = dt.predict_proba([averagesX.iloc[index]])[0] + nb.predict_proba([averagesX.iloc[index]])[0] + logReg.predict_proba([averagesX.iloc[index]])[0]\n",
    "    averageProbs = averageProbs / 3 \n",
    "\n",
    "    # print(f\"\\n\\nAVG Prediction: \\t\\t{np.argmax(averageProbs)+1}\")\n",
    "    # print(f\"Field Slice AVG Probabilities: \\t{averageProbs}\")\n",
    "    fileName = pitchingAveragesDF.iloc[index][0].replace(\",\", \"_\").replace(\" \", \"\") + \"_\" + pitchingAveragesDF.iloc[index][\"TaggedPitchType\"] + \"_\" + pitchingAveragesDF.iloc[index][\"BatterSide\"] + \"Batter\"\n",
    "    VisualUtil.visualizeData(averageProbs, [1], fileName)   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
