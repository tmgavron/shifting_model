{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training:\n",
    "# 1) Load all data from preprocessing (training/test splits, etc)\n",
    "# 2) Begin Training Models\n",
    "    #  a) Decision Tree\n",
    "    #  b) Naive Bayes\n",
    "    #  c) Logistic Regression\n",
    "    #  d) SVM\n",
    "# 3) Testing Models\n",
    "# 4) New Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from Models import ModelUtil\n",
    "from Data import Preprocessing, DataUtil\n",
    "from Visualization import VisualUtil\n",
    "from Logs import logging as logs\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import configparser\n",
    "import numpy as np\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('Data//config.ini')\n",
    "\n",
    "importlib.reload(Preprocessing)\n",
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(VisualUtil)\n",
    "importlib.reload(logs)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load all data from preprocessing \n",
    "importlib.reload(Preprocessing)\n",
    "\n",
    "if(\"False\" in config['DATA']['USE_NEW_PREPROCESSING']):\n",
    "    infieldDataFrame, outfieldDataFrame = Preprocessing.dataFiltering([], False)\n",
    "\n",
    "    # drop nan values from the used columns\n",
    "    specific_columns = [\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"PlateLocHeight\", \"PlateLocSide\", \"ZoneSpeed\", \"SpinRate\", \"RelSpeed\", \"HorzBreak\", \"VertBreak\"]\n",
    "    specific_columns = [\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"RelSpeed\", \"VertRelAngle\", \"HorzRelAngle\", \"SpinRate\", \"SpinAxis\", \"RelHeight\", \"RelSide\", \"VertBreak\", \"InducedVertBreak\", \"HorzBreak\", \"VertApprAngle\", \"HorzApprAngle\"] # pitcher averages\n",
    "    \n",
    "    infieldDataFrame = infieldDataFrame.dropna(axis=0, how='any',subset=specific_columns)\n",
    "\n",
    "else:\n",
    "    normDataFrame = Preprocessing.dataProcessing()\n",
    "    infieldDataFrame, outfieldDataFrame = Preprocessing.dataFiltering(normDataFrame, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infieldcorrmatrix = infieldDataFrame.corr()\n",
    "infieldcorrmatrix.to_csv('Infield_Correlation_Matrix')\n",
    "outfieldcorrmatrix = outfieldDataFrame.corr()\n",
    "outfieldcorrmatrix.to_csv('Outfield_Correlation_Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Class Splits (count, then percentage):\n",
      "[7280, 10890, 10257, 8471, 4956]\n",
      "[0.1739, 0.2602, 0.2451, 0.2024, 0.1184]\n",
      "\n",
      "Testing Class Splits (count, then percentage):\n",
      "[2444, 3583, 3391, 2813, 1721]\n",
      "[0.1752, 0.2568, 0.243, 0.2016, 0.1234]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(Preprocessing)\n",
    "\n",
    "if(\"False\" in config['DATA']['USE_NEW_PREPROCESSING']):\n",
    "    Y = infieldDataFrame[\"FieldSlice\"]\n",
    "    X = infieldDataFrame[[\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"PlateLocHeight\", \"PlateLocSide\", \"ZoneSpeed\", \"SpinRate\", \"RelSpeed\", \"HorzBreak\", \"VertBreak\"]] \n",
    "    X = infieldDataFrame[[\"PitcherThrows\", \"BatterSide\", \"TaggedPitchType\", \"RelSpeed\", \"VertRelAngle\", \"HorzRelAngle\", \"SpinRate\", \"SpinAxis\", \"RelHeight\", \"RelSide\", \"VertBreak\", \"InducedVertBreak\", \"HorzBreak\", \"VertApprAngle\", \"HorzApprAngle\"]] # pitcher averages\n",
    "    X = DataUtil.normalizeData(X)\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.25, random_state=11)\n",
    "    # adb = AdaBoostClassifier()\n",
    "    # adb_model = adb.fit(xTrain, yTrain)\n",
    "\n",
    "    # calculate split information:\n",
    "    trainingClassSplit = [0, 0, 0, 0, 0]\n",
    "    for i in yTrain:\n",
    "        trainingClassSplit[i-1] += 1\n",
    "\n",
    "    \n",
    "    testingClassSplit = [0, 0, 0, 0, 0]\n",
    "    for i in yTest:\n",
    "        testingClassSplit[i-1] += 1\n",
    "\n",
    "    trainingClassPercent = []\n",
    "    for i in trainingClassSplit:\n",
    "        trainingClassPercent.append(round(i/len(yTrain), 4))\n",
    "\n",
    "    testingClassPercent = []\n",
    "    for i in testingClassSplit:\n",
    "        testingClassPercent.append(round(i/len(yTest), 4))\n",
    "\n",
    "    print(\"Training Class Splits (count, then percentage):\")\n",
    "    print(trainingClassSplit)\n",
    "    print(trainingClassPercent)\n",
    "    print(\"\\nTesting Class Splits (count, then percentage):\")\n",
    "    print(testingClassSplit)\n",
    "    print(testingClassPercent)\n",
    "else:\n",
    "    infieldY = infieldDataFrame[0][['Direction','Distance']]\n",
    "    infieldX = infieldDataFrame[0][infieldDataFrame[1]] \n",
    "    if(\"True\" in config['SPLIT']['TTS']):\n",
    "        xTrain, xTest, yTrain, yTest = train_test_split(infieldX, infieldY, test_size=0.20, random_state=11)\n",
    "        \n",
    "    elif(\"True\" in config['SPLIT']['KFold']):\n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "        for train_index, test_index in kf.split(infieldX):\n",
    "            xTrain, xTest = infieldX.iloc[train_index,:], infieldX.iloc[test_index,:]\n",
    "            yTrain, yTest = infieldY.iloc[train_index,:], infieldY.iloc[test_index,:]\n",
    "\n",
    "    elif(\"True\" in config['SPLIT']['LOOCV']):\n",
    "        loo = LeaveOneOut()\n",
    "        for train_index, test_index in loo.split(infieldX):\n",
    "            xTrain, xTest = infieldX.iloc[train_index,:], infieldX.iloc[test_index,:]\n",
    "            yTrain, yTest = infieldY.iloc[train_index,:], infieldY.iloc[test_index,:]\n",
    "\n",
    "    else:\n",
    "        print(\"No Splitting Method Selected\")\n",
    "        \n",
    "\n",
    "# GroupKFold: (avoids putting data from the same group in the test set -- useful for Pitcher/Batter ID when we implement that.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training decision tree model...\n",
      "done!\n",
      "getting statistics...\n",
      "\n",
      "printing statistics...\n",
      "Model Type: DecisionTree\n",
      "\n",
      "Training Size = 41854\n",
      "Testing Size = 13952\n",
      "\n",
      "Training Accuracy = 0.3566923113680891\n",
      "Testing Accuracy = 0.3140768348623853\n",
      "\n",
      "Training Average Error = 0.9359917809528361\n",
      "Testing Average Error = 1.0002866972477065\n",
      "\n",
      "Training Recall = [0.28365384615384615, 0.5868686868686869, 0.2188749146924052, 0.3847243536772518, 0.19552058111380144]\n",
      "Testing Recall = [0.2397708674304419, 0.5266536421992744, 0.191094072544972, 0.34589406327763955, 0.1673445671121441]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.35669231136808904, 0.33214547519096194, 0.37141881175102454]\n",
      "Testing f1 (micro, macro, weighted) = [0.3140768348623853, 0.290809500307481, 0.3283532854897562]\n",
      "\n",
      "Training auc (macro, weighted) = [0.9837080055304327, 0.9807428179295563]\n",
      "Testing auc (macro, weighted) = [0.9832867295885249, 0.9798963953362626]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Max Tree Depth: 50\n",
      "Max Tree Features: 30\n",
      "Max Leaf Nodes: 150\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 0.9360\n",
      "Accuracy Score for Predicting on Test Data: 0.3141\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 17.41%\n",
      "Section 2: 25.92%\n",
      "Section 3: 24.49%\n",
      "Section 4: 20.33%\n",
      "Section 5: 11.84%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7280\t\t5229\n",
      "2\t\t10890\t\t18388\n",
      "3\t\t10257\t\t6446\n",
      "4\t\t8471\t\t9164\n",
      "5\t\t4956\t\t2627\n",
      "Amount Correct: 14929\n",
      "Amount Incorrect: 26925\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2444\t\t1801\n",
      "2\t\t3583\t\t6012\n",
      "3\t\t3391\t\t2169\n",
      "4\t\t2813\t\t3104\n",
      "5\t\t1721\t\t866\n",
      "Amount Correct: 4382\n",
      "Amount Incorrect: 9570\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# a) Decision Tree\n",
    "# Need to test these hyperparameters for best case\n",
    "max_depth = 50\n",
    "max_features = 30\n",
    "max_leaf_nodes = 150\n",
    "dtOutput = ModelUtil.runDT(xTrain, yTrain, xTest, yTest, max_depth, max_features, max_leaf_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Naive Bayes model...\n",
      "done!\n",
      "getting statistics...\n",
      "printing statistics...\n",
      "Model Type: NaiveBayes\n",
      "\n",
      "Training Size = 41854\n",
      "Testing Size = 13952\n",
      "\n",
      "Training Accuracy = 0.2886701390548096\n",
      "Testing Accuracy = 0.2907110091743119\n",
      "\n",
      "Training Average Error = 1.0867300616428537\n",
      "Testing Average Error = 1.086654243119266\n",
      "\n",
      "Training Recall = [0.34395604395604396, 0.17061524334251607, 0.3463000877449547, 0.39015464526029986, 0.17413236481033093]\n",
      "Testing Recall = [0.34083469721767595, 0.17945855428411944, 0.34915953995871424, 0.38464273018130113, 0.18245206275421266]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.2886701390548096, 0.2792573277988354, 0.2964623169150509]\n",
      "Testing f1 (micro, macro, weighted) = [0.2907110091743119, 0.28282215307660746, 0.297519100440032]\n",
      "\n",
      "Training auc (macro, weighted) = [0.9852115934664859, 0.9803946941157787]\n",
      "Testing auc (macro, weighted) = [0.9855514782258332, 0.9809961428373258]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Var Smoothing: 1e-09\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 1.0867\n",
      "Accuracy Score for Predicting on Test Data: 0.2907\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 21.10%\n",
      "Section 2: 21.02%\n",
      "Section 3: 24.87%\n",
      "Section 4: 22.12%\n",
      "Section 5: 10.89%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7280\t\t8801\n",
      "2\t\t10890\t\t5730\n",
      "3\t\t10257\t\t13894\n",
      "4\t\t8471\t\t10479\n",
      "5\t\t4956\t\t2950\n",
      "Amount Correct: 12082\n",
      "Amount Incorrect: 29772\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2444\t\t2853\n",
      "2\t\t3583\t\t1985\n",
      "3\t\t3391\t\t4614\n",
      "4\t\t2813\t\t3474\n",
      "5\t\t1721\t\t1026\n",
      "Amount Correct: 4056\n",
      "Amount Incorrect: 9896\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# b) Naive Bayes\n",
    "\n",
    "var_smoothing = 1e-9\n",
    "nbOutput = ModelUtil.runNB(xTrain, yTrain, xTest, yTest, var_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training logistic regression model...\n",
      "done!\n",
      "getting statistics...\n",
      "printing statistics...\n",
      "Model Type: LogisticRegression\n",
      "\n",
      "Training Size = 41854\n",
      "Testing Size = 13952\n",
      "\n",
      "Training Accuracy = 0.33167678119176186\n",
      "Testing Accuracy = 0.33034690366972475\n",
      "\n",
      "Training Average Error = 0.9478663926984279\n",
      "Testing Average Error = 0.9533400229357798\n",
      "\n",
      "Training Recall = [0.18612637362637363, 0.6730027548209366, 0.07643560495271522, 0.48305985125723055, 0.06497175141242938]\n",
      "Testing Recall = [0.1955810147299509, 0.6692715601451298, 0.08581539368917723, 0.47280483469605405, 0.06507844276583381]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.33167678119176186, 0.2625481245002404, 0.3832079186044943]\n",
      "Testing f1 (micro, macro, weighted) = [0.33034690366972475, 0.26547011124277786, 0.3789583609239713]\n",
      "\n",
      "Training auc (macro, weighted) = [0.9719181355342176, 0.9597177948564394]\n",
      "Testing auc (macro, weighted) = [0.9694441127666135, 0.9589056320126309]\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Learning Rate: 0.8\n",
      "Epochs: 100\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 0.9479\n",
      "Accuracy Score for Predicting on Test Data: 0.3303\n",
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 17.32%\n",
      "Section 2: 25.97%\n",
      "Section 3: 24.59%\n",
      "Section 4: 20.27%\n",
      "Section 5: 11.85%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7280\t\t3530\n",
      "2\t\t10890\t\t22101\n",
      "3\t\t10257\t\t2557\n",
      "4\t\t8471\t\t12814\n",
      "5\t\t4956\t\t852\n",
      "Amount Correct: 13882\n",
      "Amount Incorrect: 27972\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2444\t\t1165\n",
      "2\t\t3583\t\t7343\n",
      "3\t\t3391\t\t904\n",
      "4\t\t2813\t\t4250\n",
      "5\t\t1721\t\t290\n",
      "Amount Correct: 4609\n",
      "Amount Incorrect: 9343\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# c)Logistic Regression\n",
    "lr = 0.8\n",
    "e = 100\n",
    "logRegOutput = ModelUtil.runLogReg(xTrain, yTrain, xTest, yTest, lr, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM model...\n",
      "done!\n",
      "getting statistics...\n",
      "logging statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:71: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats = dftest.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:75: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:77: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats = dftrain.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:81: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing statistics...\n",
      "Model Type: SVM\n",
      "\n",
      "Training Size = 42213\n",
      "Testing Size = 14072\n",
      "\n",
      "Training Accuracy = 0.31333949257337784\n",
      "Testing Accuracy = 0.32227117680500283\n",
      "\n",
      "Training Average Error = 0.9562220169142207\n",
      "Testing Average Error = 0.9404491188175099\n",
      "\n",
      "Training Recall = [0.0, 0.8033190480532506, 0.0, 0.5206884356949193, 0.0]\n",
      "Testing Recall = [0.0, 0.8188306340927807, 0.0, 0.5387018396390142, 0.0]\n",
      "\n",
      "Training f1 (micro, macro, weighted) = [0.31333949257337784, 0.16828958750340162, 0.43098074084009164]\n",
      "Testing f1 (micro, macro, weighted) = [0.32227117680500283, 0.17354902523824683, 0.44205483936829404]\n",
      "\n",
      "Training auc (macro, weighted) = Error\n",
      "Testing auc (macro, weighted) = Error\n",
      "\n",
      "Hyper-Parameters: \n",
      "\n",
      "Regularization Constant: 1\n",
      "Kernel Type: linear\n",
      "Kernel Degree1\n",
      "Kernel Coefficient (gamma): scale\n",
      "Independent Term in Kernel (coef0): 0.0\n",
      "\n",
      "Accuracy Score for Predicting on Training Data: 0.9562\n",
      "Accuracy Score for Predicting on Test Data: 0.3223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:172: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats = dftest.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:176: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTestStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:178: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats = dftrain.groupby([\"FieldSliceActual\"]).size().reset_index()\n",
      "c:\\Users\\Trent\\Desktop\\Senior Design\\shifting_model\\Logs\\logging.py:182: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dfTrainStats[\"Correct\"] = dftemp.groupby([\"FieldSliceActual\"]).size().reset_index()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Average Probabilities\n",
      "-------------------------------------\n",
      "Section 1: 16.61%\n",
      "Section 2: 26.53%\n",
      "Section 3: 25.04%\n",
      "Section 4: 20.27%\n",
      "Section 5: 11.55%\n",
      "\n",
      "Field Slice Counts for Training Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t7295\t\t28007.0\n",
      "2\t\t10967\t\t14206.0\n",
      "3\t\t10348\t\tnan\n",
      "4\t\t8483\t\tnan\n",
      "5\t\t5120\t\tnan\n",
      "Amount Correct: 13227\n",
      "Amount Incorrect: 28986\n",
      "\n",
      "Field Slice Counts for Testing Data\n",
      "--------------------------------------------------\n",
      "Section\tTruth\tPrediction\n",
      "1\t\t2513\t\t9367.0\n",
      "2\t\t3643\t\t4705.0\n",
      "3\t\t3427\t\tnan\n",
      "4\t\t2881\t\tnan\n",
      "5\t\t1608\t\tnan\n",
      "Amount Correct: 4535\n",
      "Amount Incorrect: 9537\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ModelUtil)\n",
    "importlib.reload(logs)\n",
    "# d) SVM\n",
    "rC = 1\n",
    "kernel='linear'\n",
    "degree= 1\n",
    "gamma= 'scale'\n",
    "coef0= 0.0\n",
    "svmOutput = ModelUtil.runSVM(xTrain, yTrain, xTest, yTest, rC, kernel, degree, gamma, coef0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z) RandomForestRegressor\n",
    "for i in range(0, len(trainIn)):\n",
    "    direction, distance = ModelUtil.runRFR(trainIn[i], trainOut[i], testIn[i], testOut[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Output: \n",
      "Actual Field Slice: \t\t1\n",
      "\n",
      "Decision Tree:\n",
      "Predicted Field Slice: \t\t2\n",
      "Field Slice Probabilities: \t[0.23381643 0.35942029 0.22995169 0.12173913 0.05507246]\n",
      "\n",
      "Naive Bayes:\n",
      "Predicted Field Slice: \t\t2\n",
      "Field Slice Probabilities: \t[0.16966559 0.33103061 0.2822339  0.1707578  0.04631209]\n",
      "\n",
      "Logistic Regression:\n",
      "Predicted Field Slice: \t\t2\n",
      "Field Slice Probabilities: \t[0.21869929 0.33894116 0.24981634 0.14661964 0.04592358]\n",
      "\n",
      "\n",
      "AVG Prediction: \t\t2\n",
      "Field Slice AVG Probabilities: \t[0.20739377 0.34313069 0.25400064 0.14637219 0.04910271]\n"
     ]
    }
   ],
   "source": [
    "# Change the value of index to look at different datapoints\n",
    "importlib.reload(VisualUtil)\n",
    "# 3) Model Testing:\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "\n",
    "print(\"Testing Output: \")\n",
    "# index of test value:\n",
    "index = 6432\n",
    "print(f\"Actual Field Slice: \\t\\t{yTest.iloc[index]}\")\n",
    "\n",
    "print(\"\\nDecision Tree:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{dt.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{dt.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "print(\"\\nNaive Bayes:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{nb.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{nb.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(f\"Predicted Field Slice: \\t\\t{logReg.predict([xTest.iloc[index]])[0]}\")\n",
    "print(f\"Field Slice Probabilities: \\t{logReg.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "# print(\"\\nSVM:\")\n",
    "# print(f\"Predicted Field Slice: \\t\\t{svm.predict([xTest.iloc[index]])[0]}\")\n",
    "# print(f\"Field Slice Probabilities: \\t{svm.predict_proba([xTest.iloc[index]])[0]}\")\n",
    "\n",
    "averageProbs = dt.predict_proba([xTest.iloc[index]])[0] + nb.predict_proba([xTest.iloc[index]])[0] + logReg.predict_proba([xTest.iloc[index]])[0] # + svm.predict_proba([xTest.iloc[index]])[0]\n",
    "averageProbs = averageProbs / 3 \n",
    "\n",
    "print(f\"\\n\\nAVG Prediction: \\t\\t{np.argmax(averageProbs)+1}\")\n",
    "print(f\"Field Slice AVG Probabilities: \\t{averageProbs}\")\n",
    "\n",
    "VisualUtil.visualizeData(averageProbs, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4572\n",
      "9380\n",
      "0.207913457132854\n",
      "1.4666311300639658\n"
     ]
    }
   ],
   "source": [
    "# Gather data on average predictions\n",
    "length = len(xTest)\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "wrongProbs = 0\n",
    "wrongDistance = 0\n",
    "\n",
    "dt = dtOutput[0]\n",
    "nb = nbOutput[0]\n",
    "logReg = logRegOutput[0]\n",
    "# svm = svmOutput[0]\n",
    "for index in range(length):\n",
    "    averageProbs = dt.predict_proba([xTest.iloc[index]])[0] + nb.predict_proba([xTest.iloc[index]])[0] + logReg.predict_proba([xTest.iloc[index]])[0] #+ svm.predict_proba([xTest.iloc[index]])[0]\n",
    "    averageProbs = averageProbs / 3\n",
    "\n",
    "    actual = yTest.iloc[index]\n",
    "    predicted = np.argmax(averageProbs)+1\n",
    "\n",
    "    percentageActual = averageProbs[actual-1]\n",
    "\n",
    "    if predicted == actual:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1 \n",
    "        wrongProbs += percentageActual\n",
    "        wrongDistance += abs(actual-predicted)\n",
    "\n",
    "\n",
    "# Correct Prediction Count\n",
    "print(correct)\n",
    "# Incorrect Prediction Count\n",
    "print(incorrect)\n",
    "# Average probability of actual slice when guess is incorrect\n",
    "print(wrongProbs/incorrect)\n",
    "# Average distance from actual slice to guess slice when guess is incorrect\n",
    "print(wrongDistance/incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Model Iterations and Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Data Visualization\n",
    "\n",
    "# Temporary method of getting percentages for testing purposes\n",
    "infieldPercentages  = np.random.dirichlet(np.ones(4), size=1)[0]\n",
    "outfieldPercentages = np.random.dirichlet(np.ones(1), size=1)[0]\n",
    "\n",
    "VisualUtil.visualizeData(infieldPercentages, outfieldPercentages)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
